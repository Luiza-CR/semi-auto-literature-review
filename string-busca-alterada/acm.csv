ID,ENTRYTYPE,author,title,year,journal,booktitle,doi,url,abstract,pages
10.5555/3721488.3721770,inproceedings,"Liu, Edmond and Lim, Jong Yoon and Johnson, Vineeth and MacDonald, Bruce and Ahn, Ho Seok",SignPepper: Multimodal Social Robot for Sign Language Teaching,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Sign language is an essential communication tool, however, it can be highly challenging for non-deaf students to learn. We propose a Pepper robot based sign language teaching assistant called SignPepper, with the ability to communicate in both spoken and sign language. Using Whisper speech to text and Llama 3.3, SignPepper can engage in two way spoken lessons, with the ability to physically demonstrate signs to students. Furthermore, using 3D convolutional neural networks trained on sign language recognition, SignPepper can watch, analyze and give personalized feedback on students attempts at performing newly learned signs in real-time; including hand-based error localization.",1791–1793
10.1145/3568162.3576968,inproceedings,"Zhang, Xiajie and Breazeal, Cynthia and Park, Hae Won",A Social Robot Reading Partner for Explorative Guidance,2023,,Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568162.3576968,https://doi.org/10.1145/3568162.3576968,"Pedagogical agent research has yielded fruitful results in both academic skill learning and meta-cognitive skill acquisition, often studied in instructional or peer-to-peer paradigms. In the past decades, child-centric pedagogical research, which emphasizes the learner's active participation in learning with self-motivation, curiosity, and exploration, has attracted scholarly attention. Studies show that combining child-driven pedagogy with appropriate adult guidance leads to efficient learning and a strengthened feeling of self-efficacy. However, research on using social robots for guidance in child-driven learning still remains open and under-explored. In our study, we focus on children's exploration as the vehicle in literacy learning and develop a social robot companion that provides guidance to encourage and motivate children to explore during a storybook reading interaction. To investigate the effect of the robot's explorative guidance, we compare it against a control condition in which children have full autonomy to explore and read the storybooks. We conduct a between-subjects study with 31 children aged 4 to 6, and the result shows that children who receive explorative guidance from the social robot exhibit a growing trend of self-exploration. Further, children's self-exploration in the explorative guidance condition is found correlated to their learning outcome. We conclude the study with recommendations for designing social agents to guide children's exploration and future research directions in child-centric AI-assisted pedagogy.",341–349
10.1145/3715336.3735818,inproceedings,"Panicker, Aswati and Chung, Chia-Fang and \v{S}abanovi\'{c}, Selma",Haru in the Kitchen: Investigating Family Members’ Perceptions Toward a Social Robot Mediator of Food Experiences,2025,,Proceedings of the 2025 ACM Designing Interactive Systems Conference,10.1145/3715336.3735818,https://doi.org/10.1145/3715336.3735818,"When families live together, they often share meals, and food plays a central part in their everyday routines and rituals. When this changes and families are separated by distance, they may transition these practices to technology-mediated ones. Social robots have shown effectiveness in facilitating human-to-human interactions in various communication contexts. In this study, we explore the possibility of distant families interacting through a social robot mediator in the kitchen. We conducted 9 scenario-based interviews using the Haru social robot as a probe. Our findings highlight opportunities for food-related mediation and participants’ hesitations and concerns. We discuss how future research can address these issues, particularly in terms of how a social robot can be positioned in the family and food space, how the robot can be customized for the family’s values, and how the robot can serve as a mediator during opportune contexts (e.g., playfulness) and moments (e.g., culturally synchronous practices).",222–235
10.1145/3568162.3576957,inproceedings,"Ligthart, Mike E.U. and de Droog, Simone M. and Bossema, Marianne and Elloumi, Lamia and Hoogland, Kees and Smakman, Matthijs H.J. and Hindriks, Koen V. and Ben Allouch, Somaya",Design Specifications for a Social Robot Math Tutor,2023,,Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568162.3576957,https://doi.org/10.1145/3568162.3576957,"To benefit from the social capabilities of a robot math tutor, instead of being distracted by them, a novel approach is needed where the math task and the robot's social behaviors are better intertwined. We present concrete design specifications of how children can practice math via a personal conversation with a social robot and how the robot can scaffold instructions. We evaluated the designs with a three-session experimental user study (n = 130, 8-11 y.o.). Participants got better at math over time when the robot scaffolded instructions. Furthermore, the robot felt more as a friend when it personalized the conversation.",321–330
10.1145/3610977.3634928,inproceedings,"Gvirsman, Omer and Gordon, Goren",Effect of Social Robot's Role and Behavior on Parent-Toddler Interaction,2024,,Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610977.3634928,https://doi.org/10.1145/3610977.3634928,"Social robots, designed to interact with people through natural communication modes like speech, body motion, gestures, and facial expressions, have been extensively studied in child-robot interaction for educational purposes. Recently, social robots have been explored in triadic parent-child-robot interactions, showing promise due to their interactivity, computational power, and physical presence, which enable multimodal natural communication and cater to toddlers' developmental stages and physical curiosity. However, these have focused only on shared reading experiences and engaged older children, rather than toddlers. We developed two games, one with two levels of robot scaffolding, and another with either structured or unstructured design. We then explored, in two studies, how a social robot's assigned role and behaviors influence the engagement of parents and toddlers with the robot and their interaction with each other. Our results show that parents affectively scaffolded their children less when the robot increased its scaffolding behaviors and that parents provided more scaffolding in a structured game with the robot, whereas in an unstructured game the dyad exhibited more cooperation in which children exhibited more independence. These findings can contribute to a better understanding of interaction design, triadic dynamics, and the role of the robot in parent-toddler-robot scenario.",222–230
10.1145/3613905.3651048,inproceedings,"Milton, Matthew Charles and FakhrHosseini, Shabnam and Lee, Chaiwoo and Coughlin, Joseph",Empowering Robot Designers: A Digital Tool for Early-Stage Social Robot Prototyping and Communication,2024,,Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,10.1145/3613905.3651048,https://doi.org/10.1145/3613905.3651048,"While social robots promise to benefit people with emotional and informational needs, persistent concerns exist around their ability to effectively manage expectations and meet user needs. In this study, a digital toolkit was developed as a possible solution to support the early-stage design of social robots and address the current absence of a structured, research-informed approach. The prototype toolkit provides an interactive and visual process to assist designers of different backgrounds and varying degrees of technical knowledge; and to guide the development team throughout iterative ideation, prototyping, and communication regarding new social robot designs. The toolkit employs established human-robot interaction principles and insights from existing research to incorporate a guiding framework in the design process. This paper presents key prototype features, an outline of the user flow, a preliminary expert evaluation of the tool’s concept and usability, and future aims.",
10.1145/3568162.3576978,inproceedings,"Michaelis, Joseph E. and Cagiltay, Bengisu and Ibtasar, Rabia and Mutlu, Bilge","""Off Script:"" Design Opportunities Emerging from Long-Term Social Robot Interactions In-the-Wild",2023,,Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568162.3576978,https://doi.org/10.1145/3568162.3576978,"Social robots are becoming increasingly prevalent in the real world. Unsupervised user interactions in a natural and familiar setting, such as the home, can reveal novel design insights and opportunities. This paper presents an analysis and key design insights from family-robot interactions, captured via on-robot recordings during an unsupervised four-week in-home deployment of an autonomous reading companion robot for children. We analyzed interviews and 160 interaction videos involving six families who regularly interacted with a robot for four weeks. Throughout these interactions, we observed how the robot's expressions facilitated unique interactions with the child, as well as how family members interacted with the robot. In conclusion, we discuss five design opportunities derived from our analysis of natural interactions in the wild.",378–387
10.5555/3721488.3721698,inproceedings,"Li, Qinwei and Liu, Muyu and Peng, Xiaoying and Feng, Siyuan and Jin, Hangxu",ToiletPal: A Bathroom Interaction Robot to Mitigate Toilet Sedentary Behavior,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Toilet sedentary behavior is an often-overlooked but harmful habit that can lead to health issues like hemorrhoids. We introduce ToiletPal, a social assistive robot that encourages users to complete bathroom sessions within an ideal timeframe. Unlike timer-based reminders, ToiletPal acts as a supportive ""toilet companion,"" using an elevatable footrest, voice, and image interactions to subtly convey the passage of time. This empathetic approach fosters user-driven behavior change, contributing to SDG 3: Good Health and Well-being by promoting healthier bathroom habits and reducing sedentary behavior.",1453–1457
10.5555/3721488.3721608,inproceedings,"Shen, Jocelyn and Lee, Audrey and Alghowinem, Sharifa and Adkins, River and Breazeal, Cynthia and Park, Hae Won",Social Robots as Social Proxies for Fostering Connection and Empathy Towards Humanity,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Despite living in an increasingly connected world, social isolation is a prevalent issue today. While social robots have been explored as tools to enhance social connection through companionship, their potential as asynchronous social platforms for fostering connection towards humanity has received less attention. In this work, we introduce the design of a social support companion that facilitates the exchange of emotionally relevant stories and scaffolds reflection to enhance feelings of connection via five design dimensions. We investigate how social robots can serve as ""social proxies"" facilitating human stories, passing stories from other human narrators to the user. To this end, we conduct a real-world deployment of 40 robot stations in users' homes over the course of two weeks. Through thematic analysis of user interviews, we find that social proxy robots can foster connection towards other people's experiences via mechanisms such as identifying connections across stories or offering diverse perspectives. We present design guidelines from our study insights on the use of social robot systems that serve as social platforms to enhance human empathy and connection.",989–999
10.5555/3721488.3721648,inproceedings,"An, Dong and Rittenbruch, Markus and Razayan, Leo",The Design of Extended Reality-enabled Tangible Interaction to Enhance the Interaction with Collaborative Robots,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Collaborative robots (cobots) are increasingly employed in manufacturing to enhance productivity and efficiency, particularly by performing repetitive or precise tasks, allowing workers to focus on more complex activities. However, the growing adoption of cobots in dynamic environments, such as small and medium-sized enterprises (SMEs), poses challenges in designing flexible and user-friendly interaction models. This research addresses these challenges by integrating tangible interaction and Extended Reality (XR) technologies to develop innovative interaction methods for human-robot collaboration in metalworking. The tangible interaction leverages users' familiarity with physical objects, while XR provides immersive, real-time visual overlays to enhance task execution and decision-making. A co-design methodology is employed, involving metalworkers, XR designers, and roboticists, to ensure the system meets user needs. The study progresses through four phases: contextual inquiry, co-design workshops, system development, and user testing. Preliminary findings highlight the potential of XR-enabled tangible interaction to improve safety, efficiency, and intuitiveness in cobot applications. Future work aims to refine prototypes, evaluate scalability, and explore broader industrial applications, paving the way for safer and more effective human-robot collaboration systems.",1207–1210
10.1145/3757533,article,"Lee, Chanhee and Joung, Eunki and Koh, Youngji and Kim, Esther and Son, Sohwi and Kwon, Sunjung and Lee, Uichin", 'In That Small Space with Just the Two of Us': User Experiences with Cumpa in a Robotic Counseling Center,2025,Proc. ACM Hum.-Comput. Interact.,,10.1145/3757533,https://doi.org/10.1145/3757533,"The growing demand for mental health support has highlighted the limitations of traditional counseling accessibility, increasing the usage of digital mental health interventions. There has been a rising interest in using robots to support mental health due to their benefits in engagement and rapport. Capitalizing on the opportunity of placemaking for designing a feasible robotic digital mental health intervention, our study explores the Robot Counseling Center (RCC) and its robotic counselor, Cumpa, designed to improve mental health accessibility and user engagement. A two-week field study with 20 participants evaluated RCC's impact on their mental health, engagement, and sense of place within a counseling environment. Results indicate that RCC positively influences emotional awareness and engagement. Our findings provide insights into the role of social robots in mental health interventions and offer design implications for developing robotic counseling centers as supportive, effective spaces, contributing to building better places and interactive systems.",
10.1145/3637843.3637853,inproceedings,"Devarakonda, Sachidananda Bharadwaj and Sharma, Soumyajit Sen and Rudra Pal, Abhishek",Design and development of medical cobot to assist surgeon,2024,,Proceedings of the 2023 9th International Conference on Robotics and Artificial Intelligence,10.1145/3637843.3637853,https://doi.org/10.1145/3637843.3637853,"This paper presents an automated collaborative robot that works with a surgeon during a surgical operation incorporated with Machine learning algorithms and Deep learning algorithms to assist the surgeon by performing auxiliary actions. Our main objective is to create a framework for a collaborative nurse robot that upon voice instruction, will recognize and classify the surgical instruments present in the surgical tray and execute manual tasks such as picking up and delivering that instrument to its operator. There have been discussions on the types of co-bots and the types that can embrace the prescribed idea. After visualizing a co-bot model, designing it in CAD software is a crucial initiation to judge the practicality of the robot. The robot was designed to test its navigation before prototyping it. The main objectives to accomplish the working of an assistant medical co-bot is discussed. For object detection Aruco marker that uses Convolution Neural Network is implicated, for voice detection Google's speech recognition system having Deep neural network algorithm is embraced and for training the Co-bot using Arduino libraries is being discussed. Python has been used as a programming language and pyserial to communicate with Arduino from other two systems i.e., voice recognition system and object detection system. This medical Co-bot reflects our effort to lessen stress on surgeon and human error during operation.",38–44
10.1145/3610977.3634994,inproceedings,"Kamino, Waki and Jung, Malte F. and Sabanovi\'{c}, Selma",Constructing a Social Life with Robots: Shifting Away From Design Patterns Towards Interaction Ritual Chains,2024,,Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610977.3634994,https://doi.org/10.1145/3610977.3634994,"Robot designers commonly conceptualize robot sociality as a collection of features and capabilities. In contrast, sociologists define sociality as continuously constructed through interpersonal interactions. Based on the latter perspective, we trace how robots are incorporated into emerging social interaction ritual chains by robot companies and their staff and by robot owners across diverse contexts: homes, cafes, robot stores, user-organized meetups, and company events for robot users. Our empirical findings from ethnographic field work in Japan relating to three robots -- aibo, RoboHon, and LOVOT -- show how companies create positive interactions between people and robots by incorporating familiar design patterns into robots, modeling successful interactions in person and online, and bringing owners together in events that establish common values of acceptance of social robots as artifacts to live with and nurture. Owners, for their part, develop interaction rituals that include robots in their daily activities, make interpersonal connections, and experience emotionally resonant interactions, around robots in public meetups and events. Through these emerging interaction ritual chains, companies and owners construct the notion of robots as social agents to live with as a meaningful component of their emotional experiences and broader social relationships. Our work suggests that social robot design should consider this broader framing of sociality and create affordances for establishing interaction ritual chains more explicitly.",343–351
10.1145/3544549.3583838,inproceedings,"Ooms, Simone and Kolvenbag, Jay and Bording, Charlotte",Lighting up well-being with Bulb,2023,,Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,10.1145/3544549.3583838,https://doi.org/10.1145/3544549.3583838,"Due to the Covid-19 pandemic, two problems arose. Students lacked 1) social opportunities and 2) motivation to maintain their schedules, e.g., studying or relaxing, as their work-life balance disappeared. Thus, we designed a social companion robot, Bulb, that helped students cycle through daily activities with subtle cues, i.e., light, gaze, and movements. Bulb’s ""head"" would light up with different colors or it gazes at different parts of the room, e.g., at the laptop to hint at studying or wiggling to suggest a small break. Five students evaluated Bulb through at-home use, which demonstrated that Bulb was seen as a ""living being"" and students were responsive to its social cues, like following Bulb’s gaze, resulting in a higher awareness and follow-through of students’ schedules. Our contribution is in designing a social companion robot that subtly persuaded students through light and anthropomorphic social cues, helping them maintain their daily schedule during the pandemic.",
10.1145/3719020,article,"Zhang, Qiping and Tsoi, Nathan and Nagib, Mofeed and Choi, Booyeon and Tan, Jie and Chiang, Hao-Tien Lewis and V\'{a}zquez, Marynel",Predicting Human Perceptions of Robot Performance during Navigation Tasks,2025,J. Hum.-Robot Interact.,,10.1145/3719020,https://doi.org/10.1145/3719020,"Understanding human perceptions of robot performance is crucial for designing socially intelligent robots that can adapt to human expectations. Current approaches often rely on surveys, which can disrupt ongoing human–robot interactions. As an alternative, we explore predicting people’s perceptions of robot performance using non-verbal behavioral cues and machine learning techniques. We contribute the SEAN TOGETHER Dataset consisting of observations of an interaction between a person and a mobile robot in Virtual Reality, together with perceptions of robot performance provided by users on a 5-point scale. We then analyze how well humans and supervised learning techniques can predict perceived robot performance based on different observation types (like facial expression and spatial behavior features). Our results suggest that facial expressions alone provide useful information, but in the navigation scenarios that we considered, reasoning about spatial features in context is critical for the prediction task. Also, supervised learning techniques outperformed humans’ predictions in most cases. Further, when predicting robot performance as a binary classification task on unseen users’ data, the  (F_{1}) -Score of machine learning models more than doubled that of predictions on a 5-point scale. This suggested good generalization capabilities, particularly in identifying performance directionality over exact ratings. Based on these findings, we conducted a real-world demonstration where a mobile robot uses a machine learning model to predict how a human who follows it perceives it. Finally, we discuss the implications of our results for implementing these supervised learning models in real-world navigation. Our work paves the path to automatically enhancing robot behavior based on observations of users and inferences about their perceptions of a robot.",
10.1145/3611680,article,"Zhang, Xiajie",Designing Personalized Pedagogical AI Agents to Support Children's Exploratory Learning,2023,XRDS,,10.1145/3611680,https://doi.org/10.1145/3611680,Can a social robot support children to become better learners? How personalizing a social robot's behavior can encourage learner exploration.,16–21
10.5555/3721488.3721508,inproceedings,"Elias, Alex and Galvez Trigo, Maria J. and Camacho-Villa, Carolina",Analyzing Previous Human-Robot Interaction Implementation in Agriculture: What Can We Learn from the Past?,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"With the recent shift from conventional industrial robots to more collaborative Human-Robot Interaction (HRI) robots within industries such as the agriculture sector, it has become essential to understand the challenges associated with the adoption of these robots to ensure a smooth integration with minimal resistance. As with all new technologies, there is often push-back when changing approaches and initiating new pathways within company operations, which can cause hesitation and even halt the adoption process. This paper draws from interviews with agricultural companies that have previously attempted to implement robots requiring direct human interaction, focusing on individuals within those companies who had decision-making capabilities during the implementation process. From these interviews, a set of action principles has been developed based on transferable knowledge found within the participating companies. The main results of this user study highlight that previous implementation attempts, whether positive or negative, influence future adoption. The study also identifies the multitude of barriers surrounding the agricultural sector's adoption of these technologies and suggests potential actions for companies to take to minimize the issues associated with implementing HRI robots. By identifying common successes and failures and contextualizing them for other companies to follow, this study aims to utilize lessons learned from past implementation attempts to shorten the learning curve and reduce hesitation in adopting HRI robots within the agricultural sector.",123–131
10.5555/3721488.3721635,inproceedings,"Williams, Tom",Improvising Interaction: Toward Applied Improvisation Driven Social Robotics Theory and Education,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Theater-based design methods are seeing increased use in social robotics, as embodied roleplay is an ideal method for designing embodied interactions. Yet theater-based design methods are often cast as simply one possible tool; there has been little consideration of the importance of specific improvisational skills for theater-based design; and there has been little consideration of how to train students in theater-based design methods.We argue that improvisation is not just one possible tool of social robot design, but is instead central to social robotics. Leveraging recent theoretical work on Applied Improvisation, we show how improvisational skills represent (1) a set of key capabilities needed for any socially interactive robot, (2) a set of learning objectives for training engineers in social robot design, and (3) a set of methodologies for training those engineers to engage in theater-based design methods.Accordingly, we argue for a reconceptualization of Social Robotics as an Applied Improvisation project; we present, as a speculative pedagogical artifact, a sample syllabus for an envisioned Applied Improvisation driven Social Robotics course that might give students the technical and improvisational skills necessary to be effective robot designers; and we present a case study in which Applied Improvisation methods were simultaneously used (a) by instructors, to rapidly scaffold engineering students' improvisational skills and (b) by those students, to engage in more effective human-robot interaction design.",1140–1148
10.1145/3762675,article,"Cuan, Catie and Jeffrey, Kyle and Kleiven, Kim and Li-Bell, Adrian and Fisher, Emre and Harrison, Matt and Holson, Benjie and Okamura, Allison and Bennice, Matt",Interactive Multi-Robot Flocking with Gesture Responsiveness and Musical Accompaniment,2025,J. Hum.-Robot Interact.,,10.1145/3762675,https://doi.org/10.1145/3762675,"For decades, robotics researchers have pursued various tasks for multi-robot systems, from cooperative manipulation to search and rescue. These tasks are multi-robot extensions of classical robotic tasks and often optimized on dimensions such as speed or efficiency. As robots transition from commercial and research settings into everyday environments, social task aims such as engagement or entertainment become increasingly relevant. This work presents a designerly contribution—building a multi-robot task in which the main aim is to enthrall and interest. In this task, the goal is for a human to be drawn to move alongside and participate in a dynamic, expressive robot flock. Towards this aim, the research team created algorithms for robot movements and engaging interaction modes such as gestures and sound. The contributions are as follows: (1) a novel group navigation algorithm involving human and robot agents, (2) a gesture responsive algorithm for real-time, human–robot flocking interaction, (3) a weight mode characterization system for modifying flocking behavior, and (4) a method of encoding a choreographer’s preferences inside a dynamic, adaptive, learned system. An experiment was performed to understand individual human behavior while interacting with the flock under three conditions: weight modes selected by a human choreographer, a learned model, or subset list. Results from the experiment indicated that the perception of the experience was not influenced by the weight mode selection. This work elucidates how differing task aims such as engagement manifest in multi-robot system design and execution, and broadens the domain of multi-robot tasks.",
10.1145/3750069.3750119,inproceedings,"De Carolis, Berardina and Macchiarulo, Nicola and La Forgia, Angela and Melone, Giovanni and Nardelli, Fabio",Designing and Evaluating Rebecca: a Telepresence Robot in the Shoes of A Social Assistant for Cognitive Stimulation Therapy,2025,,Proceedings of the 16th Biannual Conference of the Italian SIGCHI Chapter,10.1145/3750069.3750119,https://doi.org/10.1145/3750069.3750119,"Social Assistive Robotics (SAR) has been successfully employed in therapeutic interventions for elderly individuals affected by cognitive impairments. However, the high cost of such systems often represents a barrier to their widespread adoption in cognitive stimulation programs targeting people with Mild Cognitive Impairment (MCI) and Mild Dementia (MD). Conversely, during the COVID-19 pandemic, telepresence robots became increasingly common in nursing homes to connect residents with caregivers and family members. Building on the availability and affordability of telepresence platforms, this study explores the transformation of a telepresence robot into a social one for use in Cognitive Stimulation Therapy (CST) within a Residential Care Facility (RCF) by developing a custom social interface. To this end, the Rebecca Social Robot Interface was designed using a User-Centered Design (UCD) approach and evaluated in a 4-week experimental study involving seven residents of an RCF enrolled in a Cognitive Stimulation Therapy (CST) program. Given the importance of ensuring intuitive and engaging interactions between the robot and older adults, measures of usability, user experience, and trust were evaluated. The HCI experts involved in the project analyzed the results of the evaluation sessions, gathered through questionnaires and observations, and used them to improve interaction usability and participant engagement. Results show that the iterative refinement of the Rebecca interface led to a good level of acceptance among the participants. The elderly users were attentive and actively involved in the tasks, indicating that a well-designed social interface can effectively foster interaction and engagement, even on low-cost telepresence robots.",
10.1145/3590837.3590903,inproceedings,"Patnaik, Amitabh and Dawar, Sunny and Kudal, Pallavi",Industry 5.0: Sustainability Challenges in Fusion of Human and AI,2023,,Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence,10.1145/3590837.3590903,https://doi.org/10.1145/3590837.3590903,"Most industrial revolutions aim to separate human labor from that of machines. These machines are referred as ""machines"" or ""robots,"" will eventually take over the majority of the labor-intensive, monotonous, or hazardous tasks currently performed by people. Cleaning robots, for instance, can efficiently clean a room or an office. Future cleaning chores will eventually all be carried out by robots; it is only a question of time. Although currently both humans and robots can perform cleaning tasks, prior data on the rate of mechanization suggests that in the future humans will perform fewer cleaning than robots. The degree of technology and public acceptance of robots determine how quickly automation permeates human lives. Studying how people and robots interact and how it affects society is crucial because robots may have a big impact on civilization. Industry 4.0 has attracted a lot of interest since its debut in 2011. Additionally, the conversation around Industry 5.0 has already begun among some academics and futurists. They present various visions of Industry 5.0. Collaboration between robots and humans is one evolving topic for Industry 5.0. People are unsure of what Industry 5.0's theme will be after some time. However, people can be certain that the coworking of humans and robots will be a significant advancement for society and have a big impact on how people conduct business. Researchers aim at contrasting Industry 4.0 with Industry 5.0 perspectives. Further researchers concentrate on the challenges which people would face when co-working between humans and robots start. Researchers finish the study by briefly discussing potential areas for future investigation.",
10.1145/3706598.3714271,inproceedings,"Xu, Jiaxin and Zhang, Chao and Cuijpers, Raymond H. and IJsselsteijn, Wijnand A.",Does Care Lead to Bonds? Exploring the Relationship Between Human Caregiving for Robots and Human-Robot Bonding,2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3714271,https://doi.org/10.1145/3706598.3714271,"This study investigates how interaction scenarios of human caregiving for robots affect humans’ perceived bond with robots. In a between-subjects lab experiment (n = 88), participants played a game with a social robot during which they provided either 1) emotional care (comforting the robot); 2) instrumental care (helping with battery charging); or 3) no care for the robot. Results indicated that caregiving did not significantly affect human-robot bonding according to explicit relationship measures including closeness, social attraction, or desire for future interaction. However, caregiving mattered when bonding was measured implicitly. Those in the emotional caregiving scenario were more hesitant to replace the robot and invested more effort in a voluntary task requested by the robot than those who provided no care. These findings provide empirical evidence that emotional caregiving interactions can effectively foster initial human-robot bonding, highlighting a promising design scenario for human-robot interaction.",
10.1145/3706029,article,"Dincer, Enes Ulas and Al-Saadi, Zaid and Hamad, Yahya M. and Aydin, Yusuf and Kucukyilmaz, Ayse and Basdogan, Cagatay",A Machine Learning Approach to Resolving Conflicts in Physical Human–Robot Interaction,2025,J. Hum.-Robot Interact.,,10.1145/3706029,https://doi.org/10.1145/3706029,"As artificial intelligence techniques become more sophisticated, we anticipate that robots collaborating with humans will develop their own intentions, leading to potential conflicts in interaction. This development calls for advanced conflict resolution strategies in physical human–robot interaction (pHRI), a key focus of our research. We use a machine learning (ML) classifier to detect conflicts during co-manipulation tasks to adapt the robot’s behavior accordingly using an admittance controller. In our approach, we focus on two groups of interactions, namely “harmonious” and “conflicting,” corresponding respectively to the cases of the human and the robot working in harmony to transport an object when they aim for the same target, and human and robot are in conflict when human changes the manipulation plan, e.g. due to a change in the direction of movement or parking location of the object.Co-manipulation scenarios were designed to investigate the efficacy of the proposed ML approach, involving 20 participants. Task performance achieved by the ML approach was compared against three alternative approaches: (a) a rule-based (RB) Approach, where interaction behaviors were rule-derived from statistical distributions of haptic features; (b) an unyielding robot that is proactive during harmonious interactions but does not resolve conflicts otherwise, and (c) a passive robot which always follows the human partner. This mode of cooperation is known as “hand guidance” in pHRI literature and is frequently used in industrial settings for so-called “teaching” a trajectory to a collaborative robot.The results show that the proposed ML approach is superior to the others in task performance. However, a detailed questionnaire administered after the experiments, which contains several metrics, covering a spectrum of dimensions to measure the subjective opinion of the participants, reveals that the most preferred mode of interaction with the robot is surprisingly passive. This preference indicates a strong inclination toward an interaction mode that gives more control to humans and offers less demanding interaction, even if it is not the most efficient in task performance. Hence, there is a clear trade-off between task performance and the preferred mode of interaction of humans with a robot, and a well-balanced approach is necessary for designing effective pHRI systems in the future.",
10.1145/3612783.3612789,inproceedings,"Ramis Guarinos, Silvia and Manresa Yee, Cristina and Buades Rubio, Jose Maria and Gaya-Morey, Francesc Xavier",Explainable Facial Expression Recognition for People with Intellectual Disabilities,2024,,Proceedings of the XXIII International Conference on Human Computer Interaction,10.1145/3612783.3612789,https://doi.org/10.1145/3612783.3612789,"Facial expression recognition plays an important role in human behaviour, communication, and interaction. Recent neural networks have demonstrated to perform well at its automatic recognition, with different explainability techniques available to make them more transparent. In this work, we propose a facial expression recognition study for people with intellectual disabilities that would be integrated into a social robot. We train two well-known neural networks with five databases of facial expressions and test them with two databases containing people with and without intellectual disabilities. Finally, we study in which regions the models focus to perceive a particular expression using two different explainability techniques: LIME and RISE, assessing the differences when used on images containing disabled and non-disabled people.",
10.1145/3631700.3665242,inproceedings,"Busia, Paola and Marche, Claudio and Meloni, Paolo and Reforgiato Recupero, Diego",Design of an AI-driven Architecture with Cobots for Digital Transformation to Enhance Quality Control in the Food Industry,2024,,"Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",10.1145/3631700.3665242,https://doi.org/10.1145/3631700.3665242,"In recent years, the rapid evolution of smart technologies has spurred enterprises to undergo digital transformations, revolutionizing their business processes and operations. This shift, known as Digital Transformation, has permeated diverse sectors, particularly impacting production systems. Notably, Artificial Intelligence (AI) and robotic automation have emerged as pivotal drivers in this transformation, promising enhanced efficiency and innovation in industrial digitization. This paper presents a novel architecture designed to facilitate digital transformation within enterprises, harnessing the capabilities of advanced collaborative robots (cobots) and cutting-edge image segmentation techniques. Focused on a practical scenario within a food production environment, our proposed architecture aims to seamlessly integrate a cobot and a camera in an automatic system for efficient cardboard disposal. Specifically, our attention is drawn to the challenge of differentiating sections of food packaging suitable for disposal from those contaminated with stains or organic residues, a task with significant implications for waste management efficiency. By leveraging a cloud-based architecture and deploying AI algorithms for image segmentation, localization, and robot guidance, our study showcases the tangible benefits and practical applicability of these methodologies in real-world settings. This research not only highlights the potential of AI-driven solutions in addressing specific industrial challenges but also underscores the broader impact of digital transformation on optimizing operational processes and driving innovation across sectors.",424–428
10.1145/3727648.3727717,inproceedings,"Ding, Yadong and Sun, Changyin and Bai, Dongming",A Novel Adaptive Enhanced Nonsingular Fast Terminal Sliding Mode Control for Collaborative Robots,2025,,"Proceedings of the 4th International Conference on Computer, Artificial Intelligence and Control Engineering",10.1145/3727648.3727717,https://doi.org/10.1145/3727648.3727717,"To realize the high tracking performance of collaborative robots, a novel adaptive nonsingular fast terminal sliding mode (NFTSM) control method is proposed in this paper. Firstly, time-delay estimation (TDE) technique is applied to estimate the complicated nonlinear dynamics and forms an excellent model-free control structure. Secondly, a novel NFTSM manifold is proposed to guarantee high accuracy and fast convergence rate. Next, A new adaptive law for the control gain is designed, which can realize gain-scheduling and suppress high-frequency noise effect. By combing TDE with the proposed NFTSM surface and adaptive law, our proposed control method can provide good control performance. Finally, two comparative experiments were conducted to show the advantages of the proposed control method over existing methods.Note to Practitioners—Due to flexibility and nonlinearity, the control problem of collaborative robots remains a challenge. Most existing methods adopt model-based control schemes, but it is difficult to obtain the dynamic model of collaborative robots, which means that model-based controller schemes are not suitable for practical applications. Therefore, this paper suggests a model-free NFTSM control scheme for collaborative robots, which can guarantee high accuracy and fast convergence rate without a dynamic model. The applicability of this method are verified through comparative experiments. In future research, we will consider adding a disturbance observer to the controller to compensate for external disturbances.",413–420
10.1145/3568162.3576999,inproceedings,"Li, Na and Ross, Robert","Hmm, You Seem Confused! Tracking Interlocutor Confusion for Situated Task-Oriented HRI",2023,,Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568162.3576999,https://doi.org/10.1145/3568162.3576999,"Our research seeks to develop a long-lasting and high-quality engagement between the user and the social robot, which in turn requires a more sophisticated alignment of the user and the system than is currently commonly available. Close monitoring of interlocutors' states, and we argue their confusion state in particular, and adjusting dialogue policies based on this state of confusion is needed for successful joint activity. In this paper, we present an initial study of human-robot conversation scenarios using a Pepper robot to investigate the confusion states of users. A Wizard-of-Oz (WoZ) HRI experiment is illustrated in detail with stimuli strategies to trigger confused states from interlocutors. For the collected data, we estimated emotions, head pose, and eye gaze, and these features were analysed against the silence duration time of the speech data and the post-study self-reported confusion states that are reported by participants. Our analysis found a significant relationship between confusion states and most of these features. We see these results as being particularly significant for multimodal situated dialogues for human-robot interaction and beyond.",142–151
10.1145/3659062,article,"Calvo-Barajas, Natalia and Akkuzu, Anastasia and Castellano, Ginevra",Balancing Human Likeness in Social Robots: Impact on Children’s Lexical Alignment and Self-disclosure for Trust Assessment,2024,J. Hum.-Robot Interact.,,10.1145/3659062,https://doi.org/10.1145/3659062,"While there is evidence that human-like characteristics in robots could benefit child-robot interaction in many ways, open questions remain about the appropriate degree of human likeness that should be implemented in robots to avoid adverse effects on acceptance and trust. This study investigates how human likeness, appearance and behavior, influence children’s social and competency trust in a robot. We first designed two versions of the Furhat robot with visual and auditory human-like and machine-like cues validated in two online studies. Secondly, we created verbal behaviors where human likeness was manipulated as responsiveness regarding the robot’s lexical matching. Then, 52 children (7–10 years old) played a storytelling game in a between-subjects experimental design. Results show that the conditions did not affect subjective trust measures. However, objective measures showed that human likeness affects trust differently. While low human-like appearance enhanced social trust, high human-like behavior improved children’s acceptance of the robot’s task-related suggestions. This work provides empirical evidence on manipulating facial features and behavior to control human likeness in a robot with a highly human-like morphology. We discuss the implications and importance of balancing human likeness in robot design and its impacts on task performance, as it directly impacts trust-building with children.",
10.5555/3545946.3598702,inproceedings,"Kim, Yubin and Chen, Huili and Algohwinem, Sharifa and Breazeal, Cynthia and Park, Hae Won",Joint Engagement Classification using Video Augmentation Techniques for Multi-person HRI in the wild,2023,,Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems,,,"Affect understanding capability is essential for social robots to autonomously interact with a group of users in an intuitive and reciprocal way. However, the challenge of multi-person affect understanding comes from not only the accurate perception of each user's affective state (e.g., engagement) but also the recognition of the affect interplay between the members (e.g., joint engagement) that presents as complex, but subtle, nonverbal exchanges between them. Here we present a novel hybrid framework for identifying a parent-child dyad's joint engagement by combining a deep learning framework with various video augmentation techniques. Using a dataset of parent-child dyads reading storybooks together with a social robot at home, we first train RGB frame- and skeleton-based joint engagement recognition models with four video augmentation techniques (General Aug, DeepFake, CutOut, and Mixed) applied datasets to improve joint engagement classification performance. Second, we demonstrate experimental results on the use of trained models in the robot-parent-child interaction context. Third, we introduce a behavior-based metric for evaluating the learned representation of the models to investigate the model interpretability when recognizing joint engagement. This work serves as the first step toward fully unlocking the potential of end-to-end video understanding models pre-trained on large public datasets and augmented with data augmentation and visualization techniques for affect recognition in the multi-person human-robot interaction in the wild. Our code and detailed experimental results are available at https://github.com/ybkim95/multi_person_joint_engagement.",698–707
10.1145/3610978.3640590,inproceedings,"Cauchard, Jessica R. and Dutau, Charles and Corsini, Gianluca and Cognetti, Marco and Sidobre, Daniel and Lacroix, Simon and Brock, Anke M.",Considerations for Handover and Co-working with Drones,2024,,Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610978.3640590,https://doi.org/10.1145/3610978.3640590,"Recent progress in aerial robotics foresees that flying robots, a.k.a. drones, can support workers in their jobs, such as by performing complex tasks in hard-to-reach places. As they become increasingly autonomous, we envision co-working drones helping human operators in direct collaborative tasks, such as by carrying tools and handing them over to workers at heights, or helping them lift and precisely position structures on construction sites. Yet, much research is needed to support safe close-body interaction between humans and drones. We here propose specific considerations for human-drone collaboration related to such handover, from the drone approaching a person in view of interacting with them at close proximity, to the handover itself, and to the drone leaving. In addition, we present the results of semi-structured interviews with three professionals in this context of human-drone collaboration. This late-breaking report highlights challenges and opportunities fostered by Human-Aerial Robot Handover (HARH).",302–306
10.1145/3594806.3594819,inproceedings,"Prajod, Pooja and Lavit Nicora, Matteo and Malosio, Matteo and Andr\'{e}, Elisabeth",Gaze-based Attention Recognition for Human-Robot Collaboration,2023,,Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments,10.1145/3594806.3594819,https://doi.org/10.1145/3594806.3594819,"Attention (and distraction) recognition is a key factor in improving human-robot collaboration. We present an assembly scenario where a human operator and a cobot collaborate equally to piece together a gearbox. The setup provides multiple opportunities for the cobot to adapt its behavior depending on the operator’s attention, which can improve the collaboration experience and reduce psychological strain. As a first step, we recognize the areas in the workspace that the human operator is paying attention to, and consequently, detect when the operator is distracted. We propose a novel deep-learning approach to develop an attention recognition model. First, we train a convolutional neural network to estimate the gaze direction using a publicly available image dataset. Then, we use transfer learning with a small dataset to map the gaze direction onto pre-defined areas of interest. Models trained using this approach performed very well in leave-one-subject-out evaluation on the small dataset. We performed an additional validation of our models using the video snippets collected from participants working as an operator in the presented assembly scenario. Although the recall for the Distracted class was lower in this case, the models performed well in recognizing the areas the operator paid attention to. To the best of our knowledge, this is the first work that validated an attention recognition model using data from a setting that mimics industrial human-robot collaboration. Our findings highlight the need for validation of attention recognition solutions in such full-fledged, non-guided scenarios.",140–147
10.1145/3650117,article,"van Den broek, Marike Koch and Moeslund, Thomas B.",What is Proactive Human-Robot Interaction? - A Review of a Progressive Field and Its Definitions,2024,J. Hum.-Robot Interact.,,10.1145/3650117,https://doi.org/10.1145/3650117,"During the past 15 years, an increasing amount of works have investigated proactive robotic behavior in relation to Human–Robot Interaction (HRI). The works engage with a variety of research topics and technical challenges. In this article, a review of the related literature identified through a structured block search is performed. Variations in the corpus are investigated, and a definition of Proactive HRI is provided. Furthermore, a taxonomy is proposed based on the corpus and exemplified through specific works. Finally, a selection of noteworthy observations is discussed.",
10.1145/3700598,article,"Aharony, Naama and Krakovski, Maya and Edan, Yael",A Transparency-Based Action Model Implemented in a Robotic Physical Trainer for Improved HRI,2024,J. Hum.-Robot Interact.,,10.1145/3700598,https://doi.org/10.1145/3700598,"Transparency is an important aspect of human–robot interaction (HRI), as it can improve system trust and usability, leading to improved communication and performance. However, most transparency models focus only on the amount of information given to users. In this article, we propose a bidirectional transparency model, termed the transparency-based action (TBA) model, which allows the robot to take actions based on transparency information received from the human (robot-of-human and human-to-robot), in addition to providing transparency information to the human (robot-to-human). To examine the impact of a three-level (High, Medium and Low) TBA model on acceptance and HRI, we first implemented the model on a robotic system trainer in two pilot studies (with students as participants). Based on the results of these studies, the Medium TBA level was not included in the subsequent main experiment, which was conducted with older adults (aged 75–85). In that experiment, two TBA levels were compared: Low (basic information including only robot-to-human transparency) and High (including additional information relating to predicted outcomes with robot-of-human and human-to-robot transparency). The results revealed a statistically significant difference between the two TBA levels of the model in terms of perceived usefulness, ease of use, and attitude. The High TBA level was preferred by users and yielded improved user acceptance.",
10.1145/3631700.3665195,inproceedings,"Kumar, Kamlesh and Chen, Yuhao and Hu, Boyi and Luo, Yue",Assessing Human Visual Attention in Retail Human-Robot Interaction: A YOLOv8-Nano and Eye-Tracking Approach,2024,,"Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",10.1145/3631700.3665195,https://doi.org/10.1145/3631700.3665195,"Objectives: This research delves into the dynamics of human-robot interaction (HRI) in retail environments, with a focus on robot detection from videos captured via an eye-tracking system. Methods: The study employs YOLOv8-nano model for real-time robot detection during grocery shopping tasks. All videos were processed using the YOLOv8 model to test inference speed while performing eye-tracking data analysis as a case study. Results: The YOLOv8 model demonstrated high precision in robot detection, with a mean average precision (mAP) of approximately 97.3% for Intersection over Union (IoU), 100% precision, and 99.87% recall for box detection. The model’s ability to process an average of 160.36 frames per second (FPS) confirmed its suitability for real-time applications. In the case study on the impact of a robot’s presence on human eye movements, the presence of a robot contributes to greater consistency in gaze fixation behavior, potentially leading to more predictable patterns of visual attention. Conclusion: The study’s findings contribute significantly to the design of safer and more efficient cobot systems. They provide a deeper understanding of human responses in real-world scenarios, which is crucial for the development of effective HRI systems.",610–615
10.1145/3706599.3716232,inproceedings,"Gollob, Emanuel and Bastan, Amir and Braumann, Johannes and Luible-Baer, Christiane",Empowering Non-Expert Users in Fashion Remanufacturing: Enhancing Human-Multi-Robot Interaction through Real-Time Visualization,2025,,Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,10.1145/3706599.3716232,https://doi.org/10.1145/3706599.3716232,"Automating textile repair and remanufacturing can significantly improve the ecological and societal impact of textiles. However, the complex behavior of textiles poses challenges for integrating robotics into fashion. This research addresses these challenges by developing a platform that empowers non-experts to define complex multi-robot tasks through visualization-enhanced hand guiding. By leveraging collaborative automation, our approach facilitates intuitive human-multi-robot interaction without extensive technical knowledge. Our approach employs flexible, parametric systems and a dual-robot setup to achieve high precision and operational flexibility in remanufacturing processes. Utilizing Grasshopper for path planning and VVVV for real-time interaction, we create a user-friendly interface allowing non-experts to interact intuitively with robots. This work demonstrates how real-time visualization can make advanced robotic capabilities accessible to non-expert users in the fashion industry. By enabling non-experts to leverage these technologies, we aim to transform remanufacturing processes and foster innovation in human-robot collaboration in the fashion and textiles sector.",
10.1145/3610978,proceedings,,HRI '24: Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,2024,,,,,"Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is ""HRI in the Real World,"" and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the ""real world"" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.",
10.1145/3746469.3746525,inproceedings,"Fang, Jitao and Chen, Xin and Liu, Ronglai and Zhan, Baocheng",Exploration and Practice in the Construction of Engineering Training Centers under the Background of Intelligent Manufacturing,2025,,Proceedings of the 2nd Guangdong-Hong Kong-Macao Greater Bay Area Education Digitalization and Computer Science International Conference,10.1145/3746469.3746525,https://doi.org/10.1145/3746469.3746525,"Intelligent manufacturing is driving profound transformations and comprehensive upgrades in the global manufacturing industry at an unprecedented pace. There is a growing demand for multidisciplinary, innovative, and globally-minded engineering talents who possess interdisciplinary integration capabilities, digital intelligence, innovative practical abilities, international perspectives, as well as engineering ethics and social responsibility. Engineering training centers serve as a bridge connecting theory and practice, and are crucial platforms for cultivating students' engineering practical abilities, innovative capabilities, and professional qualities. To meet the needs of New Engineering education, our university has actively drawn on the experiences of renowned domestic and international institutions, combining our unique educational characteristics and existing resources to comprehensively renovate, upgrade, and construct our engineering training center. Adhering to the talent cultivation philosophy of “broad scope, solid foundation, strong practice, and emphasis on innovation,"" we have established a tripartite engineering training system comprising basic engineering training platforms, advanced manufacturing technology training platforms, and intelligent engineering training platforms. This system is designed to meet the training needs for digital intelligence, interdisciplinary integration, and innovative practice. Additionally, we structured a four-tiered practical training curriculum encompassing engineering cognitive training, engineering skills training, engineering comprehensive training, and innovation and entrepreneurship training. This approach aims to achieve our talent cultivation objectives from various dimensions and provide robust support for nurturing versatile, innovative, and internationally competent engineering talents suited to the demands of intelligent manufacturing.",337–342
10.1145/3610977,proceedings,,HRI '24: Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,2024,,,,,"Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is ""HRI in the Real World,"" and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the ""real world"" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.",
10.1145/3746059.3747666,inproceedings,"Wang, Chongyang and Xia, Tianyi and Wang, Yifan and Yu, Gang and Zhao, Zixuan and Zheng, Siqi and Liao, Manqiu and Liang, Chen and Gao, Yuan and Yu, Chun and Wang, Yuntao and Shi, Yuanchun",Understanding Users' Perceptions and Expectations toward a Social Balloon Robot via an Exploratory Study,2025,,Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology,10.1145/3746059.3747666,https://doi.org/10.1145/3746059.3747666,"We are witnessing a new epoch in embodied social agents. Most of the work has focused on ground or desktop robots that enjoy technical maturity and rich social channels but are often limited by terrain. Drones, which enable spatial mobility, currently face issues with safety and proximity. This paper explores a social balloon robot as a viable alternative that combines these advantages and alleviates limitations. To this end, we developed a hardware prototype named BalloonBot that integrates various devices for social functioning and a helium balloon. We conducted an exploratory lab study on users’ perceptions and expectations about its demonstrated interactions and functions. Our results show promise in using such a robot as another form of socially embodied agent. We highlight its unique mobile and approachable characteristics that harvest novel user experiences and outline factors that should be considered before its broad applications.",
10.1145/3728199.3728285,inproceedings,"Wang, Meiping and Xia, Zongliang",Research on Artificial Intelligence in Libraries,2025,,Proceedings of the 2025 3rd International Conference on Communication Networks and Machine Learning,10.1145/3728199.3728285,https://doi.org/10.1145/3728199.3728285,"AI technology is evolving fast in many industries. However, less research has been conducted on how AI is applied in the library industry. Other than in 2022, bibliometric analysis shows that the number of library research papers has progressively increased from 2015 to 2024, with paper articles being the leading publication type in the library research industry. The dominant research area in library artificial intelligence is Computer Science. Most of the library artificial intelligence papers are published in the medical field, while the Journal of Medical Internet Research has the highest number of library artificial intelligence papers. Some of the leading nations involved in library-related AI research are the United States, China, England, and Canada. This work also further discusses the use of AI in interactive university libraries, including information retrieval, reference, library roles in artificial intelligence education for teachers and learners, and two artificial intelligence algorithms. Librarians need to up their competencies and skills for them to take full advantage of the potential use of AI in libraries.",519–526
10.1145/3670653.3677487,inproceedings,"Kassem, Khaled and Saad, Alia and Pascher, Max and Schett, Martin and Michahelles, Florian",Push Me: Evaluating Usability and User Experience in Nudge-based Human-Robot Interaction through Embedded Force and Torque Sensors,2024,,Proceedings of Mensch Und Computer 2024,10.1145/3670653.3677487,https://doi.org/10.1145/3670653.3677487,"Robots are expected to be integrated into human workspaces, which makes the development of effective and intuitive interaction crucial. While vision- and speech-based robot interfaces have been well studied, direct physical interaction has been less explored. However, HCI research has shown that direct manipulation interfaces provide more intuitive and satisfying user experiences, compared to other interaction modes. This work examines how built-in force/torque sensors in robots can facilitate direct manipulation through nudge-based interactions. We conducted a user study (N = 23) to compare this haptic approach with traditional touchscreen interfaces, focusing on workload, user experience, and usability. Our results show that haptic interactions are more engaging and intuitive but also more physically demanding compared to touchscreen interaction. These findings have implications for the design of physical human-robot interaction interfaces. Given the benefits of physical interaction highlighted in our study, we recommend that designers incorporate this interaction method for human-robot interaction, especially at close quarters.",399–407
10.1145/3715669.3727351,inproceedings,"Boluk, Nursena and Kose, Hatice",Gaze Analysis of Children with Autism During Robot-Assisted Therapy,2025,,Proceedings of the 2025 Symposium on Eye Tracking Research and Applications,10.1145/3715669.3727351,https://doi.org/10.1145/3715669.3727351,"Gaze behavior is a critical nonverbal cue for assessing attention and social engagement in children with Autism Spectrum Disorder (ASD). Gaze patterns of ten children (aged 5–10), including eight diagnosed with ASD, were examined during robot-assisted therapy sessions recorded with a fisheye camera in a naturalistic setting. The resulting EMBOA-Gaze dataset was manually annotated at both the gaze target coordinate and the semantic region, categorized as “Robot,” “Therapist,” or “Other.” Statistical analysis showed that children with ASD looked significantly more at the robot than the therapist (p =.002) and the other region (p =.030). A modular deep learning-based system was developed to predict gaze targets: head detection, region detection, and a Customized Spatio-Temporal Gaze Detection module (C-STGD). The model was trained on EMBOA-Gaze, achieving an AUC of 0.85 for point-level coordinate prediction and 75% accuracy in classifying gaze targets into semantic regions.",
10.1145/3613904.3642806,inproceedings,"Ho, Hui-Ru and Hubbard, Edward M. and Mutlu, Bilge","""It's Not a Replacement:"" Enabling Parent-Robot Collaboration to Support In-Home Learning Experiences of Young Children",2024,,Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,10.1145/3613904.3642806,https://doi.org/10.1145/3613904.3642806,"Learning companion robots for young children are increasingly adopted in informal learning environments. Although parents play a pivotal role in their children’s learning, very little is known about how parents prefer to incorporate robots into their children’s learning activities. We developed prototype capabilities for a learning companion robot to deliver educational prompts and responses to parent-child pairs during reading sessions and conducted in-home user studies involving 10 families with children aged 3–5. Our data indicates that parents want to work with robots as collaborators to augment parental activities to foster children’s learning, introducing the notion of parent-robot collaboration. Our findings offer an empirical understanding of the needs and challenges of parent-child interaction in informal learning scenarios and design opportunities for integrating a companion robot into these interactions. We offer insights into how robots might be designed to facilitate parent-robot collaboration, including parenting policies, collaboration patterns, and interaction paradigms.",
10.1145/3544549.3585696,inproceedings,"Schneiders, Eike and Papachristos, Eleftheris and van Berkel, Niels and Jacobsen, Rune M\o{}berg",“Briefly Entertaining but Pointless”: Perceived Benefits &amp; Risks of Social Robots in the Home,2023,,Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,10.1145/3544549.3585696,https://doi.org/10.1145/3544549.3585696,"In contrast to the adoption of personal assistants, social robots have yet to break into the domestic market. Several manufacturers have introduced and quickly retracted their social robots for the home. We report on a survey study (N&nbsp;=&nbsp;50) to understand potential users’ perceptions towards these social robots. Participants were presented with videos of three domestic social robots and subsequently provided their perception of these in terms of perceived benefits, attraction, privacy risk, usage intention, and capabilities. While participants perceived hedonic and utilitarian benefits, we found a low intention of future adoption of these devices. Further, our findings showed that owners of personal assistants perceived significantly higher hedonic benefits, fewer privacy risks, and higher intention to use domestic social robots. Our work provides an initial step towards understanding perceptions towards social robots and how previous exposure to domestic AI shapes users’ perceptions.",
10.1145/3643834.3660702,inproceedings,"Passler Bates, Danika and Dudek, Skyla Y. and Berzuk, James M. and Gonz\'{a}lez, Adriana Lorena and Young, James E.",SnuggleBot the Companion: Exploring In-Home Robot Interaction Strategies to Support Coping With Loneliness,2024,,Proceedings of the 2024 ACM Designing Interactive Systems Conference,10.1145/3643834.3660702,https://doi.org/10.1145/3643834.3660702,"We explored the use of three robot interaction strategies to support people living with loneliness (physical comfort, social engagement, requiring care), by building these into a robot prototype and deploying the robots into homes for long-term evaluation. We placed our original prototype, SnuggleBot, unsupervised into the homes of seven people for at least 7 weeks (optionally up to 6 months), with bi-weekly interviews, to investigate how people engage with our three robot interaction strategies. Our qualitative analysis illuminated how people engaged the robot based on all three interaction strategies. Further, some participants showed signs of bonding with the robot as well as self-reported wellbeing benefits, while some participants failed to achieve sustained use over time. Our results provide strong support for future research into robots developed with our interaction strategies, and general potential for supporting wellbeing.",2972–2986
10.1145/3613904.3642836,inproceedings,"Ashwini, B and Ghoshal, Atmadeep and Suri, Venkata Ratnadeep and Achary, Krishnaveni and Shukla, Jainendra","“It looks useful, works just fine, but will it replace me ?"" Understanding Special Educators’ Perception of Social Robots for Autism Care in India",2024,,Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,10.1145/3613904.3642836,https://doi.org/10.1145/3613904.3642836,"Social robots, particularly in assisting children with autism, have exhibited positive impacts on mental health. While prior studies concentrated on social robots in the Global North, there’s limited exploration in the Global South. It’s essential to comprehend special educators’ perspectives for effective integration in resource-constrained settings. Our mixed-methods approach, involving interviews, workshops, and a panel discussion with 25 educators in India, uncovers challenges and opportunities in integrating social robots into autism interventions. The findings highlight the urgent need to democratise the benefits of social robotics. Special educators express concerns about their functional capacity and fear potential redundancy due to the replacement of human efforts by social robots. Despite initial scepticism, professionals suggest various ways to incorporate social robots, emphasising the importance of technological innovation in reshaping and enhancing their roles in autism therapy. We discuss the implications of these findings for developing context-aware solutions and policy-level initiatives necessary in resource-constrained settings.",
10.1145/3648536.3648543,inproceedings,"Paetzel-Pr\""{u}smann, Maike and Lehman, Jill Fain and Gomez, Celia J. and Kennedy, James",An Automatic Evaluation Framework for Social Conversations with Robots,2024,,Proceedings of the 2024 International Symposium on Technological Advances in Human-Robot Interaction,10.1145/3648536.3648543,https://doi.org/10.1145/3648536.3648543,"When deploying social robots in the wild, it is crucial for developers to gain an understanding of how the interactions between the robot and its human conversational partners are progressing. Unlike in traditional task-based settings in which a human and a robot work on a tangible outcome that can serve as a proxy for how well a conversation is going, social settings require a deeper understanding of the underlying interaction dynamics. In this paper, we assess a set of recorded features of a robot having social conversations in a multi-party, multi-session setting and correlate them with how people rated their interaction. We then propose a framework that combines the features into a model that can automatically assess an ongoing conversation and determine its performance.",56–64
10.1145/3696474,proceedings,,JCRAI '24: Proceedings of the 2024 4th International Joint Conference on Robotics and Artificial Intelligence,2024,,,,,,
10.1145/3759158,article,"Axelsson, Agnes and Vaddadi, Bhavana and Bogdan, Cristian and Tobin, Deirdre and Skantze, Gabriel",Robots as Hosts in Autonomous Buses: A Field Trial,2025,J. Hum.-Robot Interact.,,10.1145/3759158,https://doi.org/10.1145/3759158,"In Autonomous Public Transport (APT), particularly with shuttle buses, passengers travel in smaller, more intimate vehicles—and in the future, such vehicles may operate without an authoritative driver or host. This setup may lead to potential safety concerns, as passengers are left alone together. Additionally, this future absence of a driver or host means that there is no one to address questions or uncertainties that may arise. One proposed solution is introducing a robot onboard the bus, serving a similar role to a human host. To explore this solution, an experiment was conducted in Barkarby, Stockholm, Sweden. Passengers, generally unfamiliar with APT or social robots, experienced two short rides on a bus equipped with either an embodied Furhat robot as the host or a disembodied voice agent in the ceiling. Data were collected from passenger-agent interactions, post-questionnaires, and semi-structured focus group interviews. Results indicate a division in passenger preferences, with some favoring the robot and others the voice assistant. Passengers asked more questions to the robot, suggesting a clearer affordance for interaction. While the questionnaires did not show significant differences, passenger behaviors indicated that they anthropomorphized the robot more. The interviews revealed that passengers felt more secure with a human operator and doubted the robot’s authority during incidents with aggressive passengers or accidents. Our findings show that social robots can help make autonomous buses feel more welcoming and interactive. Future APT systems have many design issues that need to be resolved before riders can find them safe and appropriate to use, and social robots can play a role in resolving such issues—both the ones we see today, and potentially ones that will appear in the future.",
10.1145/3715885,proceedings,,ICSeB '24: Proceedings of the 2024 8th International Conference on Software and e-Business,2024,,,,,,
10.1145/3624486.3624504,inproceedings,"Chochliouros, Ioannis P. and Pages-Montanera, Enric and Alc\'{a}zar-Fern\'{a}ndez, Aitor and Zahariadis, Theodore and Velivassaki, Terpsichori-Helen and Skianis, Charalabos and Rossini, Rosaria and Belesioti, Maria and Drosos, Nikolaos and Bakiris, Emmanouil and Pedholla, Prashanth Kumar and Karkazis, Panagiotis and Samal, Astik Kumar and Contreras Murillo, Luis Miguel and Del R\'{\i}o, Alberto and Serrano, Javier and Skias, Dimitrios and Segou, Olga E. and Waechter, Sonja",NEMO: Building the Next Generation Meta Operating System,2023,,"Proceedings of the 3rd Eclipse Security, AI, Architecture and Modelling Conference on Cloud to Edge Continuum",10.1145/3624486.3624504,https://doi.org/10.1145/3624486.3624504,"Artificial Intelligence of Things (AIoT) is one of the next big concepts to support societal changes and economic growth, being one of the fastest growing ICT segments. A specific challenge is to leverage existing technology strengths to develop solutions that sustain the European industry and values. The ongoing ΝΕΜΟ (“Next Generation Meta-Operating System”) EU-funded project intends to establish itself as the “game changer” of the AIoT-Edge-Cloud continuum by introducing an open source, modular and cybersecure meta-operating system, leveraging on existing technologies and introducing novel concepts, methods, tools, testing and engagement campaigns.NEMO will bring intelligence closer to the data and make AI-as-a-Service an integral part of network self-organisation and micro-services execution orchestration. Its widespread penetration and massive acceptance will be achieved via new technology, pre-commercial exploitation components and liaison with open-source communities.By defining a modular and adaptable mOS (meta-OS) architecture together with building blocks and plugins the project will “address” current and future technological and business needs.",1–9
10.1145/3613905.3650846,inproceedings,"Wang, Lu and Smriti, Diva and Yuan, Hao and Huh-Yoo, Jina",Artificial Intelligence Systems for Supporting Informal Caregivers of People Living with Alzheimer's Disease or Related Dementias: A Systematic Review,2024,,Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,10.1145/3613905.3650846,https://doi.org/10.1145/3613905.3650846,"Informal caregivers of people living with Alzheimer’s disease or related dementias (PLWD) face challenges like obtaining personalized information and monitoring PLWD’s health. Rapid advancements in technology, especially in sophisticated and controversial areas like artificial intelligence (AI), prompted our study to assess AI’s potential and challenges in supporting the needs of informal caregivers of PLWD. Caregiving activities require dynamic, often unpredictable, and sometimes emotionally draining tasks that deal with a large amount of information. We conducted a systematic review to understand what AI technology has been developed to support informal caregivers of PLWD. We collected 920 papers from ACM Digital Library, IEEE Xplore, and PubMed. Screening and eligibility evaluation resulted in 16 papers for full-text review. We present which documented needs of informal caregivers have been explored by the existing research, and the contexts of the AI solutions including interfaces, data, and algorithms, as well as their effectiveness, challenges, and limitations.",
10.1145/3687272,proceedings,,HAI '24: Proceedings of the 12th International Conference on Human-Agent Interaction,2024,,,,,,
10.1145/3729605.3729647,inproceedings,"Dong, Huiling and Liang, Mengdi and Song, Lingling",Research on the construction and practice of precision teaching mode of higher vocational education driven by big data,2025,,Proceedings of the 2025 International Conference on Big Data and Informatization Education,10.1145/3729605.3729647,https://doi.org/10.1145/3729605.3729647,"With the rapid development of big data technology, the field of education is undergoing major changes. The traditional ""experimental teaching"" model is gradually changing to the ""data teaching"" model. However, higher vocational education still has shortcomings in teaching and evaluation. This paper discusses the precise application of big data technology in higher vocational teaching, based on personalized learning‎[1]. Specifically, this research constructs a dynamic resource library, an intelligent learning recommendation system, and a multi-dimensional evaluation model, and conducts experiments in the course ""Electrical Control Technology"". The results showed a 12% increase in students' average grade points and a 26% increase in learning efficiency. This also shows that big data technology can solve this opposing problem of ""scale training"" and ""personality training"". This also provides a replicable example for the digital transformation of vocational education.",237–241
10.1145/3702313,article,"Vinueza-Naranjo, Paola G. and Chicaiza, Janneth and Rumipamba-Zambrano, Ruben",Fog Computing Technology Research: A Retrospective Overview and Bibliometric Analysis,2024,ACM Comput. Surv.,,10.1145/3702313,https://doi.org/10.1145/3702313,"Researchers’ interest in Fog Computing and its application in different sectors has been increasing since the last decade. To discover the emerging trends inherent to this architecture, we analyzed the scientific literature indexed in Scopus through a bibliometric study. Exposing trends in areas of development will allow researchers to understand the changes and evolution over time. For analysis purposes, we used three approaches: performance analysis, science mapping, and literature clustering. Analysis results revealed promising investigation areas in the Fog Computing architecture from 2012 to 2021, which emphasizes that Fog Computing will continue to be an interesting field of research in the future.",
10.1145/3628096.3629060,inproceedings,"Mapharisa, Maneo",Co-designed Robots towards African Challenges by Basotho Children,2024,,Proceedings of the 4th African Human Computer Interaction Conference,10.1145/3628096.3629060,https://doi.org/10.1145/3628096.3629060,"As technology and Human-Computer Interaction spread across Africa, young children have been attracted to creative designs. This interactive submission showcases three robots that have been developed by High School Children. We are excited to showcase the achievements of the High School students, who have developed three remarkable robots that address real-world challenges. These robots are the result of dedication, creativity, and hard work, and we believe they hold great potential to inspire and captivate the attendees of the conference. Our interactive design provides a firsthand experience of these robots in action developed by children. They have been meticulously designed to solve daily problems faced by individuals, showcasing how technological advancements can enhance our lives. From assisting with household chores to tackling environmental concerns, these robots demonstrate the incredible possibilities when young minds are encouraged to explore the intersection of technology and problem-solving. All the robots designers' age ranges between 11 -16 years old. The children will be able to present, demonstrate, and explain the developed robots.",238–240
10.1145/3696593.3696612,inproceedings,"Ded\`{o}, Shana and Esposito, Andrea and Guedes, Leandro S. and Landoni, Monica",Voices That Matter: An Exploratory Study on Technology Preferences and Challenges Among People with Intellectual Disabilities,2025,,Proceedings of the 11th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion,10.1145/3696593.3696612,https://doi.org/10.1145/3696593.3696612,"With the increasing interest of several accessibility researchers in the development of technological tools to better support people with intellectual disabilities in their day-to-day lives, it is becoming more and more important to understand the point of view of those directly involved. Although the number of studies conducted with the participation of users with intellectual disabilities has increased in recent years, there are still many questions we need to ask, starting from the preferences and challenges experienced by this group of individuals. For this reason, the present exploratory study aims to bring to light, through semi-structured interviews, the preferences and difficulties that two target groups - clients and staff members from a support centre in Italy - currently have regarding the use and utility of technology within their daily life. In this work, we describe the methodologies and insights emerging from the thematic analysis of the collected data from the interviews, enabling us to better understand and inform the design of more accessible technology for all.",301–310
10.5555/3721488.3721605,inproceedings,"Antony, Victor Nikhil and Stiber, Maia and Huang, Chien-Ming","Xpress: A System For Dynamic, Context-Aware Robot Facial Expressions using Language Models",2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Facial expressions are vital in human communication and significantly influence outcomes in human-robot interaction (HRI), such as likeability, trust, and companionship. However, current methods for generating robotic facial expressions are often labor-intensive, lack adaptability across contexts and platforms, and have limited expressive ranges-leading to repetitive behaviors that reduce interaction quality, particularly in long-term scenarios. We introduce Xpress, a system that leverages language models (LMs) to dynamically generate context-aware facial expressions for robots through a three-phase process: encoding temporal flow, conditioning expressions on context, and generating facial expression code. We demonstrated Xpress as a proof-of-concept through two user studies (n=15x2) and a case study with children and parents (n=13), in storytelling and conversational scenarios to assess the system's context-awareness, expressiveness, and dynamism. Results demonstrate Xpress's ability to dynamically produce expressive and contextually appropriate facial expressions, highlighting its versatility and potential in HRI applications.",958–967
10.1145/3610978.3640722,inproceedings,"Jansen, Chipp and Ma, Zhengtao and Hatfield, Lissy and Tuo, Boyuan and Ozden Yenigun, Elif and Baurley, Sharon and Wang, Stephen Jia and Lee, Kun Pyo",Textile Robotic Interaction for Designer-Robot Collaboration,2024,,Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610978.3640722,https://doi.org/10.1145/3610978.3640722,"This late-breaking report describes lab-based robot experiments involving two robot arms scanning and interaction with a set of 12 novel sustainable materials programmed with handfeel gestures inspired by how designers evaluate textile materials. The aim of gathering this data is to spur research in robot perception of soft materials and to contribute towards human-robot collaborative design systems. The complete dataset including scanned images, video of interactions accompanied by the robot motion paths is available with code at https://github.com/rca-msrc/textile-robotic-interaction-HRI2024.",563–567
10.5555/3721488.3721832,inproceedings,"Ravindranath, Sindhu and Tanevska, Ana and Chandra, Shruti and Korpan, Raj and Eguchi, Amy","4th Diversity, Equity, &amp; Inclusion in HRI Workshop",2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"It is crucial to prioritize diversity, equity, and inclusion (DEI) in the development of AI and robotics. Neglecting these factors not only exacerbates existing discrimination and biases, but also continues perpetuating them over time. Despite global awareness, urgent action is needed within the human-robot interaction (HRI) community. This workshop aims to bridge the gap by providing a platform for sharing experiences and research insights related to identifying, addressing, and integrating DEI principles in HRI. Building upon its last few iterations, this year's workshop will actively involve participants in tackling human biases which can be transferred to the robots, aiming to mitigate inequity, recognize and minimize prejudice, and promote inclusion within the field of HRI.",1982–1984
10.5555/3721488.3721794,inproceedings,"Kamino, Waki",Robots in the Deep Wild: Ethnography of People's Everyday Lives with Social Robots,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"My research explores how robots become meaningful parts of people's lives by examining the social, technical, and cultural ecologies of consumer robots. Based on ethnographic fieldwork primarily conducted in Japan, I investigate how robots like aibo, LOVOT, and RoBoHoN are integrated into daily routines and relationships. My findings challenge the conventional focus on design features in HRI, advocating for a broader understanding of human-robot interaction that includes the social practices and human labor sustaining long-term engagement.",1860–1862
10.1145/3613905.3648628,inproceedings,"Kim, Minsol and Nallbani, Aliea L and Stovall, Abby Rayne",Exploring LLM-based Chatbot for Language Learning and Cultivation of Growth Mindset,2024,,Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,10.1145/3613905.3648628,https://doi.org/10.1145/3613905.3648628,"Growth mindset, the belief in enhancing abilities through effort and dedication, is commonly applied in classroom learning. The Mindset Theory Scale suggests it can be measured by ""effort"" and ""belief in improvement"", while fixed mindset is indicated by ""procrastination"" and ""immutability of belief"". In today’s interconnected world, the need for proficiency in multiple languages has grown. However, mastering different languages poses several challenges, including motivational challenges and fear of failure. To address this issue, our study explores the use of an adaptable Large Language Model (LLM) based chatbot to foster growth mindset and aid in language learning. In a user study with this novel chatbot system, we evaluated the impact of a growth mindset teaching style on new language learning and user perception. Our initial findings show that users are more comfortable, confident, and interested in interacting with the growth mindset chatbot compared to the fixed mindset chatbot.",
10.1145/3648536,proceedings,,TAHRI '24: Proceedings of the 2024 International Symposium on Technological Advances in Human-Robot Interaction,2024,,,,,,
10.5555/3721488.3721532,inproceedings,"Malnatsky, Elena and Ligthart, Mike E.U.",Fitting Humor: Age-Based Personalization for Shaping Relatable Child-Robot Interactions,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"In this paper, we present a participatory design approach to age-based personalization for child-robot interaction. This is an important step towards social robots being effective across age groups. As a testbed for our approach, we used humor. Personalized humor is a powerful social motivator and is uniquely suited to build relatable and sustained child-robot interactions.Through a series of co-design workshops (n = 102 children), we identified humor concepts that fit the specific sense of humor for each of the four age groups (8-9, 9-10, 10-11, 11-12 y.o.), as well as humor concepts that resonated across these age groups. A user study showed that, overall, children found the interaction more amusing and a better fit for both their own sense of humor and that of their peer group when the robot used age-personalized humor compared to age-agnostic humor. The strength of the effects varied by age group, with the oldest group consistently scoring lower on the outcome measures, indicating that the design was not equally effective for all groups.",331–341
10.1145/3647817,proceedings,,ICBBS '23: Proceedings of the 2023 12th International Conference on Bioinformatics and Biomedical Science,2023,,,,,,
10.1145/3706598.3714169,inproceedings,"Zhang, Xiaoyu and Xue, Fei and Albers, Alexander and Netland, Torbj\""{o}rn","""It's impressive, but in practice..."": Experiencing a Realistic Digital Transformation in and beyond the Classroom",2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3714169,https://doi.org/10.1145/3706598.3714169,"Serious games, particularly board games, have long been employed in production management education to teach various concepts. While they have demonstrated educational effectiveness, their integration with emerging Industry 4.0 technologies remains limited. Furthermore, there is a lack of empirical research on how industry practitioners apply these digitization technologies in the workplace. To bridge this gap, we designed a course that integrates digital technologies into a traditional board game. We conducted two studies to evaluate both knowledge gains within the classroom and knowledge transfer back into the manufacturing industry. Our results show an improved understanding of the synergies between production management principles and Industry 4.0 technologies, as well as the real-world challenges students face when attempting to transfer this knowledge. Our work contributes pedagogical and practical perspectives on how technology-enhanced serious games can extend learning in and beyond the classroom.",
10.5555/3721488.3721510,inproceedings,"Kamino, Waki and \v{s}abanovi\'{c}, Selma and Jung, Malte F.", 'A Robot's Life is Over When People Give Up': Socio-Technical Infrastructure for Sustaining Consumer Robots,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Sustenance of long-term human-robot relationships relies on a socio-technical infrastructure of care and repair, in which both technical maintenance and social practices work together to sustain robots as relational objects. This infrastructure is, however, often invisible and taken for granted while working well. It is in moments of breakdown and repair that the necessary infrastructure that supports long-term human-robot relationships is exposed. In this paper, we present ethnographic fieldwork and stakeholder interviews with eight users and eight producers and repair staff of successful consumer robots in Japan, that highlight the often-overlooked moments of technological breakdown and the meaning-making that surrounds them. This allows us to shed light on the evolving components of the socio-technical infrastructure-such as technical processes, cultural norms, shared language, emotional labor, and interpersonal relationships-that are essential for sustaining the functionality and relevance of robots in people's everyday lives.",142–151
10.1145/3746027.3755463,inproceedings,"Bian, Tongfei and Chollet, Mathieu and Guha, Tanaya",Robust Understanding of Human-robot Social Interactions through Multimodal Distillation,2025,,Proceedings of the 33rd ACM International Conference on Multimedia,10.1145/3746027.3755463,https://doi.org/10.1145/3746027.3755463,"There is a growing need for social robots and intelligent agents that can effectively interact with and support users. For the interactions to be seamless, the agents need to analyse social scenes and behavioural cues from their (robot's) perspective. Works that model human-agent interactions in social situations are few; and even those existing ones are computationally too intensive to be deployed in real time or perform poorly in real-world scenarios when only limited information is available. We propose a knowledge distillation framework that models social interactions through various multimodal cues, and yet is robust against incomplete and noisy information during inference. We train a teacher model with multimodal input (body, face and hand gestures, gaze, raw images) that transfers knowledge to a student model which relies solely on body pose. Extensive experiments on two publicly available human-robot interaction datasets demonstrate that our student model achieves an average accuracy gain of 14.75% over competitive baselines on multiple downstream social understanding tasks, even with up to 51% of its input being corrupted. The student model is also highly efficient - less than 1% in size of the teacher model in terms of parameters and its latency is 11.9% of the teacher model. Our code and related data are available at github.com/biantongfei/SocialEgoMobile.",5726–5734
10.1145/3711936,article,"Khaksar, Weria and Lindblom, Diana Saplacan and Bygrave, Lee Andrew and Torresen, Jim",Robotics in Elderly Healthcare: A Qualitative Analysis of 20 Recent European Research Projects,2025,J. Hum.-Robot Interact.,,10.1145/3711936,https://doi.org/10.1145/3711936,"Studies foresee a dramatic increase in the elderly population of Western Europe over the next decades, putting pressure on healthcare systems. Healthcare robots are developed to facilitate independent living for elderly people. This article aims to provide a qualitative analysis of recent projects in healthcare robotics (2008–2024) and proposes new research directions for healthcare robots for older adults. We provide an overview of current research and a roadmap for upcoming research. Our study began with a literature search using four databases. Searches were performed for articles from research projects containing the words “elderly care,” “assisted aging,” “health monitoring,” or “elderly health.” Additional exclusion criteria were used to focus on elderly healthcare and utilization of commercial robotic systems. Resulting from this endeavor, 20 recent research projects are described and categorized in this article. Then, these projects were analyzed using thematic analysis. Our findings are summarized in common themes: Most projects have a strong bias towards care robots’ functionalities; robots are often seen as outsiders in care settings; there is an emphasis on robots as commercial products; and there is some limited attention to the design and ethical aspects of care robots, but very little attention to their legal aspects. The article concludes with key points representing a roadmap for future research addressing robotics for the elderly.",
10.5555/3721488.3721540,inproceedings,"Alzahrani, Abdullah and Nasir, Jauwairia and Tayeb, Ahmad J. and Andr\'{e}, Elisabeth and Ahmad, Muneeb I.",What Do the Face and Voice Reveal? Investigating Trust Dynamics During Human-Robot Interaction,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Existing research has shown that vocal and non-vocal human cues correlate with human trust and distrust behaviours, suggesting their potential to measure human trust in robots in real-time. However, there is a lack of research in Human-Robot Interaction that integrates vocal and non-vocal cues into a comprehensive model to measure trust. This paper aims to estimate human trust in robots by examining vocal and non-vocal cues differences between trust and distrust states across multiple sessions of collaborative game-based HRI with 40 participants. Our analysis revealed that vocal and non-vocal human cues can indeed predict trust in HRI, with certain facial expressions, facial movements, and pitch being significant factors. Random Forest classifier achieved the highest accuracy (84%) in classifying trust states, with key features such as facial expressions (fear, angry), facial blendshapes (cheekSquintRight, jawRight), and vocal characteristics (Duration, Harmonicity std) being the most predictive of trust. These findings demonstrate the importance of combining vocal and non-vocal cues for accurate trust measurement and highlight the potential for real-time trust assessment in robotic systems.",400–409
10.1145/3706598.3713978,inproceedings,"Gomez-Beldarrain, Garoa and Verma, Himanshu and Kim, Euiyoung and Bozzon, Alessandro",Why does Automation Adoption in Organizations Remain a Fallacy?: Scrutinizing Practitioners' Imaginaries in an International Airport,2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3713978,https://doi.org/10.1145/3706598.3713978,"In organizations, the interest in automation is long-standing. However, adopting automated processes remains challenging, even in environments that appear highly standardized and technically suitable for it. Through a case study in Amsterdam Airport Schiphol, this paper investigates automation as a broader sociotechnical system influenced by a complex network of actors and contextual factors. We study practitioners’ collective understandings of automation and subsequent efforts taken to implement it. Using imaginaries as a lens, we report findings from a qualitative interview study with 16 practitioners involved in airside automation projects. Our findings illustrate the organizational dynamics and complexities surrounding automation adoption, as reflected in the captured problem formulations, conceptions of the technology, envisioned human roles in autonomous operations, and perspectives on automation fit in the airside ecosystem. Ultimately, we advocate for contextual automation design, which carefully considers human roles, accounts for existing organizational politics, and avoids techno-solutionist approaches.",
10.1145/3643834.3661519,inproceedings,"Hu, Yuhan and Lu, Jasmine and Scinto-Madonich, Nathan and Pineros, Miguel Alfonso and Lopes, Pedro and Hoffman, Guy","Designing Plant-Driven Actuators for Robots to Grow, Age, and Decay",2024,,Proceedings of the 2024 ACM Designing Interactive Systems Conference,10.1145/3643834.3661519,https://doi.org/10.1145/3643834.3661519,"Designing plant-driven actuators presents an opportunity to create new types of devices that grow, age, and decay, such as robots that embody these qualities in their physical structure. Plant-robot hybrids that grow and decay incorporate unpredictable and gradual transformations inherent across living organisms and suggest an alternative to the design principles of immediacy, responsiveness, control, accuracy, and durability commonly found in robotic design. To explore this, we present a design space of primitives for plant-driven robotic actuators. Proof-of-concept prototypes illustrate how concepts like slow change, slow movement, decay, and destruction can be incorporated into robotic forms. We describe the design considerations required for building plant-driven actuators for robots, including experimental findings regarding the mechanical properties of plant forces. Finally, we speculate on the potential benefits of plant-robot hybrids to interactive domains such as robotics.",2481–2496
10.1145/3727990,article,"Karaosmanoglu, Eda and Rozendaal, Marco C. and Alcubilla Troughton, Irene and Bleeker, Maaike and Vallery, Heike and Cramm, Jane Murray",Exploring the Potential of Spherical Robots to Promote Physical Activity at Home: A Pattern Language,2025,J. Hum.-Robot Interact.,,10.1145/3727990,https://doi.org/10.1145/3727990,"Social robots have become increasingly prominent in the realm of physical activity promotion. However, the technological complexity and primarily anthropomorphic designs of these robots pose challenges for their application in everyday settings. This study positions spherical robots as an emerging subtype of social robots and explores their potential to promote physical activity at home by identifying useful behavioral design patterns. To this end, we engaged theater professionals and human-robot interaction researchers in a 4-day workshop, leveraging a speculative design methodology. A puppeteer controlling a robotic ball and two actors improvised human-robot encounters in a staged home setting. These encounters were analyzed to identify instances where the ball triggered physical activity. From this analysis, we extracted nine design patterns that articulate robot behaviors for initiating physical interaction. Additionally, our findings revealed that these patterns could be combined into complex sequences to sustain physical activities, which are experienced as meaningful when framed within a narrative. We discuss the contents of these patterns and their potential value for home-based healthcare applications. Our contribution lies in articulating the potential of spherical robots for promoting physical activity at home through design patterns informed by a performative approach to human-robot interaction.",
10.1145/3589659,article,"Leong, Joanne",Using Generative AI to Cultivate Positive Emotions and Mindsets for Self-Development and Learning,2023,XRDS,,10.1145/3589659,https://doi.org/10.1145/3589659,The arrival of new generative AI tools is creating waves. Here are some ideas for how we could channel them for supporting self-development and learning.,52–56
10.1145/3706599.3719980,inproceedings,"Ungless, Eddie L. and Ross, Bj\""{o}rn and Horne, Zachary","""Till I can get my satisfaction"": Open Questions in the Public Desire to Punish AI",2025,,Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,10.1145/3706599.3719980,https://doi.org/10.1145/3706599.3719980,"There are countless examples of how AI can cause harm, and increasing evidence that the public are willing to ascribe blame to the AI itself, regardless of how “illogical” this might seem. This raises the question of whether and how the public might expect AI to be punished for this harm. However, public expectations of the punishment of AI have been vastly underexplored. Understanding these expectations is vital, as the public may feel the lingering effect of harm unless their desire for punishment is satisfied. We synthesise research from psychology, human-computer and -robot interaction, philosophy and AI ethics, and law to highlight how our understanding of this issue is still lacking. We call for an interdisciplinary programme of research to establish how we can best satisfy victims of AI harm, for fear of creating a “satisfaction gap” where legal punishment of AI (or not) fails to meet public expectations.",
10.1145/3570731,article,"Robinson, Nicole and Tidd, Brendan and Campbell, Dylan and Kuli\'{c}, Dana and Corke, Peter",Robotic Vision for Human-Robot Interaction and Collaboration: A Survey and Systematic Review,2023,J. Hum.-Robot Interact.,,10.1145/3570731,https://doi.org/10.1145/3570731,"Robotic vision, otherwise known as computer vision for robots, is a critical process for robots to collect and interpret detailed information related to human actions, goals, and preferences, enabling robots to provide more useful services to people. This survey and systematic review presents a comprehensive analysis on robotic vision in human-robot interaction and collaboration (HRI/C) over the past 10&nbsp;years. From a detailed search of 3,850 articles, systematic extraction and evaluation was used to identify and explore 310 papers in depth. These papers described robots with some level of autonomy using robotic vision for locomotion, manipulation, and/or visual communication to collaborate or interact with people. This article provides an in-depth analysis of current trends, common domains, methods and procedures, technical processes, datasets and models, experimental testing, sample populations, performance metrics, and future challenges. Robotic vision was often used in action and gesture recognition, robot movement in human spaces, object handover and collaborative actions, social communication, and learning from demonstration. Few high-impact and novel techniques from the computer vision field had been translated into HRI/C. Overall, notable advancements have been made on how to develop and deploy robots to assist people.",
10.1145/3585088.3589354,inproceedings,"Xu, Ying and He, Kunlei and Vigil, Valery and Ojeda-Ramirez, Santiago and Liu, Xuechen and Levine, Julian and Cervera, Kelsyann and Warschauer, Mark",“Rosita Reads With My Family”: Developing A Bilingual Conversational Agent to Support Parent-Child Shared Reading,2023,,Proceedings of the 22nd Annual ACM Interaction Design and Children Conference,10.1145/3585088.3589354,https://doi.org/10.1145/3585088.3589354,"Bilingual children have unique needs for school readiness as they navigate between two languages and cultures. A supportive home language environment, where children are frequently exposed to language through conversation and reading, can positively impact their language development and prepare them for school. However, current conversational agents and e-books designed for children do not typically take into account the cultural and linguistic needs of bilingual children and do not involve parents. This project presents the development of a bilingual conversational agent and accompanying e-book, designed to support parent-child interactions and promote language development for Latinx Spanish-English bilingual children. Results from a user study indicate that the bilingual agent effectively engages children verbally and encourages parental involvement in reading processes. The study also provides design insights for creating conversational agents for bilingual children.",160–172
10.1145/3610978.3640563,inproceedings,"Avalos, Samantha and Granados, Carlos and Tafur, Mayli and Arroyo, Dante and Roncal, Silvia Julissa",Allybot: Design Studio to Enhance Girls' Participation in Technology and Art,2024,,Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610978.3640563,https://doi.org/10.1145/3610978.3640563,"This study introduces AllyBot, an educational robot tailored for early adolescent girls in Peru, aiming to empower them in the domains of Technology and Art. With a focus on collaborative learning, AllyBot enhances the quality of education and contributes to gender equity by providing progressive experiences that foster self-esteem and confidence. The proposed approach incorporates group activities, personalized interactions, and positive feedback mechanisms, creating a supportive environment aligned with the National Curriculum of Peru. This research emphasizes the role of AllyBot in shaping an inclusive educational landscape, fostering a more equitable and enriched learning experience for girls.",219–222
10.1145/3610978.3640607,inproceedings,"Jain, Chirag and Brown, Hunter L. and Knight, Heather",DRAWBOT: Making Everyday Objects Interactive,2024,,Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610978.3640607,https://doi.org/10.1145/3610978.3640607,"In various public settings, such as coffee shops, individuals often experience boredom while waiting in lines, a problem exacerbated by the lack of engaging and interactive experiences. This paper introduces DRAWBOT: Drawing Robotic Assistant for the Withering of Boredom or Tediousness. The project aims to address the challenge of uneventful waiting times by deploying a roboticized furniture system that encourages artistic expression in people.",554–558
10.1145/3610977.3634934,inproceedings,"Sica, Arianna and S\ae{}tra, Henrik S.",Artificial Emotions and the Evolving Moral Status of Social Robots,2024,,Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610977.3634934,https://doi.org/10.1145/3610977.3634934,"This article aims to explore the potential impact of artificial emotional intelligence (AEI) on the ethical standing of social robots. By examining how AEI interacts with and potentially reshapes the two dominant perspectives on robots' moral status, namely the property-oriented approach and the social-relational approach, we aim to offer fresh insights into this pressing dilemma. Our analysis reveals that although the incorporation of AEI does not conclusively confer moral status to current social robots, it might challenge the boundaries that separate robots from other entities customarily considered to have more status, thereby increasing the complexity of the debate.",649–657
10.1145/3623509.3635863,inproceedings,"Avalos, Samantha and Granados, Carlos and Tafur, Mayli and Arroyo, Dante and Roncal, Silvia Julissa",AllyBot: Empowering Girls Participation in STEAM,2024,,"Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction",10.1145/3623509.3635863,https://doi.org/10.1145/3623509.3635863,"This paper introduces the study of AllyBot, an educational robot aimed at empowering Peruvian girls in STEAM fields. Focused on middle childhood, AllyBot promotes collaborative learning, embraces mistakes, and offers progressive experiences to foster self-esteem and confidence. Through group activities, customization, and positive feedback, it creates a supportive environment for girls to develop essential skills. The envisioned scenario integrates art, mathematics, science, and environmental topics from Peru’s National Curriculum. AllyBot’s user-assembled design, customizable components, and emotional expressions emphasize human-robot interaction dynamics, highlighting the importance of fostering self-efficacy through dialogue.",
10.1145/3708319,proceedings,,"UMAP Adjunct '25: Adjunct Proceedings of the 33rd ACM Conference on User Modeling, Adaptation and Personalization",2025,,,,,,
10.1145/3610978.3641261,inproceedings,"Toczek, Maisey and Dossett, Benjamin and Rhodes, Cora and Hessler, Matthew and Mamo, Robel and Haring, Kerstin",Brush-E Bot: Your Toothbrushing Companion Bot,2024,,Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610978.3641261,https://doi.org/10.1145/3610978.3641261,"Cavities is a common disease children experience and consistent brushing has been found to reduce the chances of cavities developing. Despite the importance of brushing many caretakers face resistance when trying to instill consistent brushing habits in children. By making brushing time more fun, children can create positive associations with brushing, establishing habits that can last a lifetime. Enter Brush-E Bot! Our robot is designed to make brushing engaging and educational, teaching children how to brush correctly while making the experience as fun as possible. In this paper we discuss the importance, design, implementation, and contribution of our robot.",1261–1264
10.1145/3688852,article,"Benjamin, Victor",Considering Socially Scalable Human-Robot Interfaces,2024,ACM Trans. Manage. Inf. Syst.,,10.1145/3688852,https://doi.org/10.1145/3688852,"Collaborative robots are becoming increasingly present in everyday life, with applications ranging food and parcel delivery, security, and more. They can offer great value propositions for organizations and consumers. However, most people lack knowledge of how to interact with robots, and many robots themselves necessitate formal training that can be inaccessible to many and thus not societally scalable. Further, there is a lack of existing work investigating interfaces designs that can support non-dyadic interactions consisting of two or more individuals interacting with a robot sequentially and simultaneously; such interactions will be common in real-world usage. This research explores the efficacy of natural language interfaces for human–robot interaction through a human experiment and post-experiment survey. Results show that the natural language interface can afford teams enhanced capabilities to share robot control and avoid errors relative to other interfaces, while also increasing user perceptions towards overall interaction.",
10.1145/3585088,proceedings,,IDC '23: Proceedings of the 22nd Annual ACM Interaction Design and Children Conference,2023,,,,,,
10.1145/3660244,article,"Schnitzer, Benjamin and Vural, Umut Can and Schnitzer, Bastian and Sardar, Muhammad Usman and Fuerst, Oren and Korn, Oliver",Prototyping a Zoomorphic Interactive Robot Companion with Emotion Recognition and Affective Voice Interaction for Elderly People,2024,Proc. ACM Hum.-Comput. Interact.,,10.1145/3660244,https://doi.org/10.1145/3660244,"An aging society paired with a skilled labor shortage, particularly in European countries, requires a rethinking of deprecated structures. Intelligent assistive technologies, specifically socially assistive robots, addressing the gap between caretakers and elderly people in need of care have moved into the focus of debate due to their potentials to reduce costs, improve independence, and eventually raise quality of life. In this work, we outline the potentials of zoomorphic robot companions combining intelligent conversational abilities and emotion recognition. We then describe the prototyping of an emotion-sensing zoomorphic interactive robot companion including the development and implementation of a multimodal emotion recognition framework. This framework uses speech emotion recognition, sentiment analysis, and affective voice interaction based on a large language model. The prototyping has been accompanied by two studies on elderly peoples' design preferences regarding the proposed feature set as well as different embodiments to find the appropriate casing for the robot companion. This work provides valuable insights into the prototyping and can thus support future research endeavors in this area.",
10.1145/3726986,proceedings,,OzCHI '24: Proceedings of the 36th Australasian Conference on Human-Computer Interaction,2024,,,,,,
10.1145/3665689.3665737,inproceedings,"Shang, Huichao and Zhang, Xiao and Li, Penglei",Visualization analysis of medical robot research in the past 20 years,2024,,Proceedings of the 2024 4th International Conference on Bioinformatics and Intelligent Computing,10.1145/3665689.3665737,https://doi.org/10.1145/3665689.3665737,"Medical robot research is one of the important research directions in the field of robotics. By searching the Web of Science core collection database, the relevant literature on medical robot research from January 1,2002 to December 31,2022 was retrieved and used as a research sample. Using CiteSpace software combined with VOSviewer and Pajek software for visual analysis, identify and analyze its research status, research hotspots and evolution trends, and predict its development direction. Finally, we found that the research institutions cooperate more, but there are regional constraints. The research hotspots mainly focus on the research of surgical robot, mechanical design and system development, and the deep integration of robot and medical treatment. In recent years, the keywords of related literature in this field mainly include Artificial intelligence, human-computer interaction, software robots, care and so on. Research on telemedicine, AI assistance, and flexible wearables are some of the future development directions in this field.",280–286
10.1145/3568294.3580115,inproceedings,"Luo, Yue and Chen, Yuhao and Hu, Boyi",Multisensory Evaluation of Human-Robot Interaction in Retail Stores - The Effect of Mobile Cobots on Individuals' Physical and Neurophysiological Responses,2023,,Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568294.3580115,https://doi.org/10.1145/3568294.3580115,"As more mobile collaborative robots (cobots) are being deployed in domestic environments, it is necessary to ensure safety while interacting with humans. To this end, a better understanding of individuals' physical and neurophysiological responses (i.e., short term adaptation) during those interactions becomes crucial to frame the cobot's behavioral and control algorithms. The primary objective of this study was to assess individuals' physical and neurophysiological responses to the mobile cobot in a retail environment. Eight participants were recruited to complete typical grocery shopping tasks (i.e., cart pushing, item picking, and item sorting) with and without a mobile robot running in the same space. Results showed the co-existence of mobile cobot in the retail environment stimulated individuals' physical responses, by significantly changing their upper-limb kinematics, i.e., reducing the average flexion angles of L5/S1, T12/L1, and right shoulder in the sagittal plane. However, no significant differences were observed in the neurophysiological adaptation based on the measures of muscle activity of the latissimus dorsi, anterior deltoid, and bicep brachii, nor the pupil diameter.",403–406
10.1145/3641554.3701907,inproceedings,"Hinojosa, Cesar and Kumar, Priyanka and Rajarajan, Pragathi Durga and Martin, Fred",TrainYourSnakeAI: A Novel Tool to Teach Reinforcement Learning to Middle School Students,2025,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,10.1145/3641554.3701907,https://doi.org/10.1145/3641554.3701907,"Artificial Intelligence (AI) is growing rapidly in our society and is now apparent in our day-to-day lives. With the recent burst of interest in AI, many individuals and children may view AI as something mystic and magical. It is important to demystify and introduce to them how AI is made and works. To address this need, we developed a software application that allows children to specify the parameters used by a Reinforcement Learning (RL) algorithm. Then students experience how RL is used to train an AI model to play the game ""Snake."" This software tool was tested with 71 middle school-age students. Here, we describe the design of the TrainYourSnakeAI application, the approach we used to introduce the associated ideas to middle school children, and how we assessed student learning. Qualitative data collected from students are presented and discussed. We surveyed their knowledge of AI before and after using the application. In this work, our research questions were: (RQ1) How can we create an engaging tool to teach reinforcement learning? and (RQ2) Does using our application foster a stronger understanding of reinforcement learning in children? Our findings indicate that students were able to understand the functionality of reward functions and how agents can learn from the environment using the concept of RL. We found that out of the 51 students who were not previously familiar with RL, 40 were able to provide adequate descriptions of RL after using TrainYourSnakeAI.",506–512
10.1145/3610978.3640761,inproceedings,"Correia, Filipa and Neto, Isabel and Fortes-Ferreira, Margarida and Oogjes, Doenja and Almeida, Teresa",More-than-human Perspective on the Robomorphism Paradigm,2024,,Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610978.3640761,https://doi.org/10.1145/3610978.3640761,"This paper proposes a posthuman perspective of the robomorphism theory. We propose to define robomorphism as the attribution of robotlike traits to non-robotic entities. Such a definition embraces the centrality of robots in two aspects. First, by assuming the target of robomorphism is not necessarily a human. Second, by considering the notion of robomorphic traits as inherently crucial to establish the robomorphism paradigm. Embracing robots as relevant non-humans in the robomorphism paradigm constitutes the more-than-human perspective of the proposed approach. The contributions of this paper are threefold. First, we propose the robomorphism paradigm by defining it and its inherent concepts, such as robomorphisation and robomorphic. Second, we discuss the broader implications of the robomorphism theory to the research community of Human-Robot Interaction, raising important new challenges. Third, we created a preliminary inventory of robomorphic traits, which were collected from a speculative workshop activity in order to start answering one of the proposed open challenges.",11–19
10.1145/3568162.3576958,inproceedings,"Axelsson, Agnes and Skantze, Gabriel",Do You Follow? A Fully Automated System for Adaptive Robot Presenters,2023,,Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568162.3576958,https://doi.org/10.1145/3568162.3576958,"An interesting application for social robots is to act as a presenter, for example as a museum guide. In this paper, we present a fully automated system architecture for building adaptive presentations for embodied agents. The presentation is generated from a knowledge graph, which is also used to track the grounding state of information, based on multimodal feedback from the user. We introduce a novel way to use large-scale language models (GPT-3 in our case) to lexicalise arbitrary knowledge graph triples, greatly simplifying the design of this aspect of the system. We also present an evaluation where 43 participants interacted with the system. The results show that users prefer the adaptive system and consider it more human-like and flexible than a static version of the same system, but only partial results are seen in their learning of the facts presented by the robot.",102–111
10.1145/3652988,proceedings,,IVA '24: Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents,2024,,,,,,
10.1145/3610978.3640721,inproceedings,"Sayis, Batuhan and Gunes, Hatice",Technology-assisted Journal Writing for Improving Student Mental Wellbeing: Humanoid Robot vs. Voice Assistant,2024,,Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610978.3640721,https://doi.org/10.1145/3610978.3640721,"Conversational agents have a potential in improving student mental wellbeing while assisting them in self-disclosure activities such as journalling. Their embodiment might have an effect on what students disclose, and how they disclose this, and student's overall adherence to the disclosure activity. However, the effect of embodiment in the context of agent assisted journal writing has not been studied. Therefore, this study aims to investigate the viability of using social robots (SR) and voice assistants (VA) for eliciting rich disclosures in journal writing that contributes to mental health status improvement in students over time. Forty two undergraduate and graduate students participated in the study that assessed the mood changes (via Brief Mood Introspection Scale, BMIS), level of subjective self-disclosure (via Subjective Self-Disclosure Questionnaire, SSDQ), and perceptions toward the agents (via Robot Social Attributes Scale, RoSAS) with and without agent (SR or VA) assisted journal writing. Results suggest that only in robot condition there are mood improvements, higher levels of disclosure, and positive perceptions over time in technology-assisted journal writing. Our results suggest that robot assisted journal writing has some advantages over voice assistant one for eliciting rich disclosures that contributes to mental health status improvement in students over time.",945–949
10.1145/3594315.3594641,inproceedings,"Jiang, Zhenxiang",A Novel Seven-Class Facial Expression Recognition Method With Face Mask,2023,,Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence,10.1145/3594315.3594641,https://doi.org/10.1145/3594315.3594641,"Since COVID-19, face masks have become essential in people’s lives. When people are wearing masks, it is incredibly difficult for traditional face recognition techniques to identify facial expression. This paper proposes a seven-class facial expression recognition dataset FM-FER2013 (Face-Masked FER2013). The FM-FER2013 dataset is based on the FER2013 dataset. I also proposed a facial expression recognition method with face mask, based on YOLOv5 for face detection and ResNet for facial expression recognition. The accuracy are about 60% on the seven-class FM-FER2013 dataset and 73% on the five-class FM-FER2013 dataset. And then, real-world test is performed, with accuracy around 65%. The proposed method’s effectiveness and robustness demonstrate its high value and provide a hint for real-world application. The code implement is shown in https://github.com/RoyMikeJiang/FM-FER2013.",178–184
10.1145/3631358.3631363,article,"Shrestha, Sarahana and Varde, Aparna S.","Roles of the Web in Commercial Energy Efficiency: IoT, Cloud Computing, and Opinion Mining",2023,SIGWEB Newsl.,,10.1145/3631358.3631363,https://doi.org/10.1145/3631358.3631363,"The overconsumption of energy in recent times has motivated many studies. Some of these explore the application of web technologies and machine learning models, aiming to increase energy efficiency and reduce the carbon footprint. This paper aims to review three areas that overlap between the web and energy usage in the commercial sector: IoT (Internet of Things), cloud computing and opinion mining. The paper elaborates on problems in terms of their causes, influences, and potential solutions, as found in multiple studies across these areas; and intends to identify potential gaps with the scope for further research. In the rapidly digitizing and automated world, these three areas can offer much contribution towards reducing energy consumption and making the commercial sector more energy efficient. IoT and smart manufacturing can assist much in effective production, and more efficient technologies as per energy usage. Cloud computing, with reference to its impact on green IT (information technology), is a major area that contributes towards the mitigation of carbon footprint and the reduction of costs on energy consumption. Opinion mining is significant as per the part it plays in understanding the feelings, requirements and demands of the consumers of energy as well as the related stakeholders, so as to help create more suitable policies and hence navigate towards more energy efficient strategies. This paper offers comprehensive analyses on the literature in the concerned areas to fathom the current status and explore future possibilities of research across these areas and the related multidisciplinary avenues.",
10.1145/3750069,proceedings,,CHItaly '25: Proceedings of the 16th Biannual Conference of the Italian SIGCHI Chapter,2025,,,,,,
10.5555/3721488.3721632,inproceedings,"Esposito, Raffaella and Rossi, Alessandra and Ponticorvo, Michela and Rossi, Silvia",RoboLeaks: Non-strategic Cues for Leaking Deception in Social Robots,2025,,Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction,,,"Deception is a complex phenomenon that is deeply intertwined with human social interactions. Deception between humans often manifests through verbal, vocal, and visible behaviors. While it often has unethical implications, it can also serve valuable social functions, such as maintaining relationships, protecting emotions, or managing difficult situations. For this reason, it is also being investigated in robotic applications. In this work, we propose a framework for implementing specific robot behaviors through non-strategic cues of deception (known as leakage), during deceptive communication with humans. We dwell on the ethical dimensions of robotic deception by acknowledging the implication of possible physical or psychological harm in sensitive contexts, such as healthcare and assistive robotics. We propose to mitigate possible drops in trust towards robots using more transparent and human-like deceptive behaviors, by equipping robots with seemingly unintentional behaviors that betray deception. To this extent, we propose a low-risk educational scenario where a robot interacts with students in a problem-solving game to test deception leaking's effects on students' perceptions of the robot, perceived human-likeness, intentionality, engagement, and trust in the robot.",1111–1120
10.1145/3583849.3583853,article,"Conti, Christopher J. and Varde, Aparna S. and Wang, Weitian","Web Perspectives in Robotics Applications: Commonsense Knowledge, Autonomous Vehicles and Human-Robot Collaboration",2023,SIGWEB Newsl.,,10.1145/3583849.3583853,https://doi.org/10.1145/3583849.3583853,"The realms of commonsense knowledge and reasoning, vehicle automation with full as well as partial autonomy, and human-robot collaboration, present growing areas of research in recent times, with much of the concerned data being disseminated through the Web and devices encompassing IoT (Internet of Things); the data per se being heterogeneous including plain text, images, audiovisuals, hypertext and hypermedia. Due to the advent of autonomous vehicles, there is a greater need for the embodiment of commonsense knowledge within their development in order to simulate subtle, intuitive aspects of human judgment. The field of robotics has often encountered collaborative tasks between humans and robots to enhance the respective activities involved and produce better results than humans or robots would achieve working by themselves. Accordingly, this article outlines and organizes some of the research occurring in these areas along with its Web perspectives and applications. Context related to human-robot collaboration and commonsense knowledge appears via a survey of the literature. Vehicle automation is significant with the relevant studies: its definition and methods of improvement are of focus in the article. Some work in this area makes an impact on smart manufacturing. There is discussion on how human-robot collaboration is beneficial, and how commonsense knowledge is useful for the collaboration to occur in an enhanced manner. This article would be potentially interesting to various communities, e.g. AI professionals, Web developers, robotics engineers, and data scientists.",
10.1145/3706598.3713582,inproceedings,"Lima, Maria R. and O'Connell, Amy and Zhou, Feiyang and Nagahara, Alethea and Hulyalkar, Avni and Deshpande, Anura and Thomason, Jesse and Vaidyanathan, Ravi and Matari\'{c}, Maja",Promoting Cognitive Health in Elder Care with Large Language Model-Powered Socially Assistive Robots,2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3713582,https://doi.org/10.1145/3706598.3713582,"As the global population ages, there is increasing need for accessible technologies that promote cognitive health and detect early signs of cognitive decline. This research demonstrates the potential for in-residence monitoring and assessment of cognitive health using large language model (LLM)-powered socially assistive robots (SARs). We conducted a 5-week within-subjects study involving 22 older adults in retirement homes to investigate the feasibility of large language model (LLM)-powered socially assistive robots (SARs) for promoting and assessing cognitive health. We designed tasks that involved verbal dialogue based on clinically validated cognitive tools. Our findings reveal improved task performance after three robot-administered sessions, with significantly more detailed picture descriptions, fewer word repetitions in semantic fluency, and reduced need for hints. We found that older adults were more socially engaged in robot-administered tasks compared to those administered by a human, and they accepted and were willing to engage with socially assistive robots (SARs) in this context, which had not been tested before.",
10.1145/3706598.3713755,inproceedings,"Yuan, Shuai and Coghlan, Simon and Lederman, Reeva and Waycott, Jenny","Meaningful Engagement, Ethical Care, and Design Opportunities: An Ethnographic Study on Social Activities in Long-term Care",2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3713755,https://doi.org/10.1145/3706598.3713755,"Social activities in long-term care homes help promote residents’ wellbeing, but their effectiveness depends on residents’ engagement. To identify design opportunities for promoting meaningful engagement, we conducted an ethnographic study on organised activities in an Australian aged care home. We observed staff fostered engagement by initiating conversations, weaving residents’ backgrounds into interactions, and adapting activities to residents’ varying abilities. However, challenges included new staff members’ unfamiliarity with residents, multi-tasking, and insufficient support to engage excluded residents. Using a care ethics lens that includes relational, situated and empathetic features of care, we show that meaningful engagement is shaped by the ethical care practices embedded in staff-resident interactions and highlight opportunities for technologies to mitigate barriers hindering staff from providing ethical care in existing activities. These opportunities include: collecting and recording residents’ interests, providing conversation prompts, enhancing activity inclusiveness, and reducing language and cultural barriers.",
10.1145/3715336.3735765,inproceedings,"Pham, Tuan Vu and Weisswange, Thomas H. and Hassenzahl, Marc","Impact of Affirmative and Negating Robot Gestures on Perceived Personality, Role, and Contribution of a Human Group Member",2025,,Proceedings of the 2025 ACM Designing Interactive Systems Conference,10.1145/3715336.3735765,https://doi.org/10.1145/3715336.3735765,"Robots can play a role in mediating human group interactions. This study examines how robot gestures affect the perception of a human group member’s personality, role in the group, and contribution. In a vignette study (n=96), participants imagined being in a group discussion and watched a short video of another group member presenting an argument. In one condition (affirmative gesture), a robot nodded while the member spoke; in the other, it shook its head (negating gesture). A control condition featured no robot. The affirmative gesture enhanced perceptions of the speaker’s personality and role in the group, though their contribution was not affected. The negating gesture showed no adverse effects. Additionally, participants perceived the robot as a group member when it nodded but as an onlooker when it shook its head. This suggests that positive robot gestures can improve group dynamics by fostering favorable interpersonal perceptions.",271–286
10.1145/3696271,proceedings,,MLMI '24: Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI),2024,,,,,,
10.1145/3594806,proceedings,,PETRA '23: Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments,2023,,,,,,
10.1145/3568294.3580048,inproceedings,"Axelsson, Minja and Spitale, Micol and Gunes, Hatice",Robotic Coaches Delivering Group Mindfulness Practice at a Public Cafe,2023,,Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568294.3580048,https://doi.org/10.1145/3568294.3580048,"Group meditation is known to keep people motivated and committed over longer periods of time, as compared to individual practice. Robotic coaching is a promising avenue for engaging people in group meditation and mindfulness exercises. However, the deployment of robotic coaches to deliver group mindfulness sessions in real-world settings is very scarce. We present the first steps in deploying a robotic mindfulness coach at a public cafe, where participants could join robot-led meditation sessions in a group setting. We conducted two studies with two robotic coaches: the toy-like Misty II robot for 4 weeks (n = 4), and the child-like QTrobot for 3 weeks (n = 3). This paper presents an exploratory qualitative analysis of the data collected via group discussions after the sessions, and researcher observations during the sessions. Additionally, we discuss the lessons learned and future work related to deploying a robotic coach in a real-world group setting.",86–90
10.1145/3626705,proceedings,,MUM '23: Proceedings of the 22nd International Conference on Mobile and Ubiquitous Multimedia,2023,,,,,,
10.1145/3746175,proceedings,,ECCE '25: Proceedings of the 36th Annual Conference of the European Association of Cognitive Ergonomics,2025,,,,,,
10.1145/3743049,proceedings,,MuC '25: Proceedings of the Mensch und Computer 2025,2025,,,,,,
10.1145/3708557,proceedings,,IUI '25 Companion: Companion Proceedings of the 30th International Conference on Intelligent User Interfaces,2025,,,,,,
10.1145/3708359.3712112,inproceedings,"Pataranutaporn, Pat and Archiwaranguprok, Chayapatr and Chan, Samantha W. T. and Loftus, Elizabeth and Maes, Pattie",Slip Through the Chat: Subtle Injection of False Information in LLM Chatbot Conversations Increases False Memory Formation,2025,,Proceedings of the 30th International Conference on Intelligent User Interfaces,10.1145/3708359.3712112,https://doi.org/10.1145/3708359.3712112,"This study examines the potential for malicious generative chatbots to induce false memories by injecting subtle misinformation during user interactions. An experiment involving 180 participants explored five intervention conditions following the presentation of an article: (1) no intervention, (2) reading an honest or (3) misleading article summary, (4) discussing the article with an honest or (5) misleading chatbot. Results revealed that while the misleading summary condition increased false memory occurrence, misleading chatbot interactions led to significantly higher rates of false recollection. These findings highlight the emerging risks associated with conversational AI as it becomes more prevalent. The paper concludes by discussing implications and proposing future research directions to address this concerning phenomenon.",1297–1313
10.1145/3612783,proceedings,,Interacci\'{o}n '23: Proceedings of the XXIII International Conference on Human Computer Interaction,2023,,,,,,
10.1145/3544548.3581245,inproceedings,"Jain, Eakta and Gardner-McCune, Christina",Horse as Teacher: How human-horse interaction informs human-robot interaction,2023,,Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,10.1145/3544548.3581245,https://doi.org/10.1145/3544548.3581245,"Robots are entering our lives and workplaces as companions and teammates. Though much research has been done on how to interact with robots, teach robots and improve task performance, an open frontier for HCI/HRI research is how to establish a working relationship with a robot in the first place. Studies that explore the early stages of human-robot interaction are an emerging area of research. Simultaneously, there is resurging interest in how human-animal interaction could inform human-robot interaction. We present a first examination of early stage human-horse interaction through the lens of human-robot interaction, thus connecting these two areas. Following Strauss’ approach, we conduct a thematic analysis of data from three sources gathered over a year of field work: observations, interviews and journal entries. We contribute design guidelines based on our analyses and findings.",
10.5555/3716662.3716664,inproceedings,"Akbulut, Canfer and Weidinger, Laura and Manzini, Arianna and Gabriel, Iason and Rieser, Verena",All Too Human? Mapping and Mitigating the Risks from Anthropomorphic AI,2025,,"Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society",,,"The development of highly-capable conversational agents, underwritten by large language models, has the potential to shape user interaction with this technology in profound ways, particularly when the technology is anthropomorphic, or appears human-like. Although the effects of anthropomorphic AI are often benign, anthropomorphic design features also create new kinds of risk. For example, users may form emotional connections to human-like AI, creating the risk of infringing on user privacy and autonomy through over-reliance. To better understand the possible pitfalls of anthropomorphic AI systems, we make two contributions: first, we explore anthropomorphic features that have been embedded in interactive systems in the past, and leverage this precedent to highlight the current implications of anthropomorphic design. Second, we propose research directions for informing the ethical design of anthropomorphic AI. In advancing the responsible development of AI, we promote approaches to the ethical foresight, evaluation, and mitigation of harms arising from user interactions with anthropomorphic AI.",13–26
10.1145/3581791.3597506,inproceedings,"Blanco, Alejandro","Towards Precise, Ubiquitous and Real-Time Positioning",2023,,"Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services",10.1145/3581791.3597506,https://doi.org/10.1145/3581791.3597506,"Positioning is an enabler for many location-based services in the vertical industrial domain such as autonomous driving and robot-to-cobot interaction, to name a few. Industry and academia are actively enabling localization through 5G and WiFi as they are universally deployed. However, the current WiFi and 5G protocols cannot deal with the hard requirements of accuracy, latency, and robustness. To deal with that, we have proposed a series of works to enable precise, pervasive, and real-time positioning.",615–617
10.1145/3626774,article,"Bakhshalipour, Mohammad and Gibbons, Phillip B.",Agents of Autonomy: A Systematic Study of Robotics on Modern Hardware,2023,Proc. ACM Meas. Anal. Comput. Syst.,,10.1145/3626774,https://doi.org/10.1145/3626774,"As robots increasingly permeate modern society, it is crucial for the system and hardware research community to bridge its long-standing gap with robotics. This divide has persisted due to the lack of (i) a systematic performance evaluation of robotics on different computing platforms and (ii) a comprehensive, open-source, cross-platform benchmark suite.To address these gaps, we present a systematic performance study of robotics on modern hardware and introduce RoWild, an open-source benchmark suite for robotics that is comprehensive and cross-platform. Our workloads encompass a broad range of robots, including driverless vehicles, pilotless drones, and stationary robotic arms, and we evaluate their performance on a spectrum of modern computing platforms, from low-end embedded CPUs to high-end server-grade GPUs. The source code of the benchmark suite is available in https://cmu-roboarch.github.io/rowild/.Our findings reveal that current architectures experience significant inefficiencies when executing robotic workloads, highlighting the need for architectural advancements that satisfy the primary requirements of robotic tasks. We discuss approaches for meeting these requirements, offering insights for improving the performance of robotics.",
10.1145/3657242,proceedings,,Interacci\'{o}n '24: Proceedings of the XXIV International Conference on Human Computer Interaction,2024,,,,,,
10.1145/3584871,proceedings,,ICSIM '23: Proceedings of the 2023 6th International Conference on Software Engineering and Information Management,2023,,,,,,
10.1145/3696593,proceedings,,DSAI '24: Proceedings of the 11th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion,2024,,,,,,
10.1145/3702163,proceedings,,ICETC '24: Proceedings of the 2024 16th International Conference on Education Technology and Computers,2024,,,,,,
10.1145/3643834.3660737,inproceedings,"La Delfa, Joseph and Garrett, Rachael and Lampinen, Airi and H\""{o}\""{o}k, Kristina",How to Train Your Drone: Exploring the umwelt as a design metaphor for human-drone interaction,2024,,Proceedings of the 2024 ACM Designing Interactive Systems Conference,10.1145/3643834.3660737,https://doi.org/10.1145/3643834.3660737,"How To Train Your Drone is a novel human-drone interaction that demonstrates the generative potential of a design metaphor: the umwelt. We describe the concept of the umwelt and detail how we applied it to inform our soma design process, creating an interactive space where somatic understandings between human and drone could emerge. The system was deployed for a month into a shared household. We describe how three people explored and shaped the umwelts of their drones, leading to unique and intimate human-drone couplings. We discuss the compatibility of the umwelt to soma design practice and identify future avenues for research inspired by artificial life and evolutionary robotics. As our contribution, we illustrate how the umwelt as a design metaphor, can open up a generative new design space for human-drone interaction.",2987–3001
10.1145/3653912,proceedings,,"IEEA '24: Proceedings of the 2024 13th International Conference on Informatics, Environment, Energy and Applications",2024,,,,,,
10.1145/3568162.3578626,inproceedings,"Kaduk, Julian and Cavdan, M\""{u}ge and Drewing, Knut and Vatakis, Argiro and Hamann, Heiko",Effects of Human-Swarm Interaction on Subjective Time Perception: Swarm Size and Speed,2023,,Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568162.3578626,https://doi.org/10.1145/3568162.3578626,"Many large-scale multi-robot systems require human input during operation in different applications. To still minimize the human effort, interaction is intermittent or restricted to a subset of robots. Despite this reduced demand for human interaction, the mental load and stress can be challenging for the human operator. A specific effect of human-swarm interaction may be a hypothesized change of subjective time perception in the human operator. In a series of simple human-swarm interaction experiments with robot swarms of up to 15 physical robots, we study whether human operators have altered time perception due to the number of controlled robots or robot speeds. Using data gathered by questionnaires, we found that increased swarm size shrinks perceived time and decreased robot speeds expand the perceived time. We introduce the concept of subjective time perception to human-swarm interaction. Future research will enable swarm systems to autonomously modulate subjective timing to ease the job of human operators.",456–465
10.1145/3638380,proceedings,,OzCHI '23: Proceedings of the 35th Australian Computer-Human Interaction Conference,2023,,,,,,
10.1145/3720553,proceedings,,HT '25: Proceedings of the 36th ACM Conference on Hypertext and Social Media,2025,,,,,,
10.1145/3715336,proceedings,,DIS '25: Proceedings of the 2025 ACM Designing Interactive Systems Conference,2025,,,,,,
10.1145/3626314,article,"Perez-Cerrolaza, Jon and Abella, Jaume and Borg, Markus and Donzella, Carlo and Cerquides, Jes\'{u}s and Cazorla, Francisco J. and Englund, Cristofer and Tauber, Markus and Nikolakopoulos, George and Flores, Jose Luis",Artificial Intelligence for Safety-Critical Systems in Industrial and Transportation Domains: A Survey,2024,ACM Comput. Surv.,,10.1145/3626314,https://doi.org/10.1145/3626314,"Artificial Intelligence (AI) can enable the development of next-generation autonomous safety-critical systems in which Machine Learning (ML) algorithms learn optimized and safe solutions. AI can also support and assist human safety engineers in developing safety-critical systems. However, reconciling both cutting-edge and state-of-the-art AI technology with safety engineering processes and safety standards is an open challenge that must be addressed before AI can be fully embraced in safety-critical systems. Many works already address this challenge, resulting in a vast and fragmented literature. Focusing on the industrial and transportation domains, this survey structures and analyzes challenges, techniques, and methods for developing AI-based safety-critical systems, from traditional functional safety systems to autonomous systems. AI trustworthiness spans several dimensions, such as engineering, ethics and legal, and this survey focuses on the safety engineering dimension.",
10.1145/3582580.3582618,inproceedings,"Sun, Yujie",The Application of Artificial Technology in Research and Practical Education,2023,,Proceedings of the 2022 5th International Conference on Education Technology Management,10.1145/3582580.3582618,https://doi.org/10.1145/3582580.3582618,"In recent years, the rapid development of information technology has made digital research travel an inevitable trend in the innovative development of research practice. resources are vivid teaching materials for ideological and political education for young people. Based on the era of digital economy, this paper discusses the connotation of information technology in research practice education, analyzes the current situation of youth research, and deeply studies the application dilemma of information technology in research practice education. Through the design of ""smart restaurant"", the culture is spread by modern high-tech means; through the analysis of experimental design, the application strategies of information technology in the research and practice education of smart restaurant are summarized, so as to maximize the use of culture in the era of digital economy. The guiding role of research and practical education for contemporary young people.",210–217
10.1145/3679318.3685346,inproceedings,"van Ledden, Sebastian and Lisetschko, Artur and Jansen, Nadine and Jendrusch, Dagmar and Hermann, Julia and Dogang\""{u}n, Ayseg\""{u}l",User-Centric Design of Social Robots in City Libraries: Exploration of the Interplay of Social Roles and User Expectations,2024,,Proceedings of the 13th Nordic Conference on Human-Computer Interaction,10.1145/3679318.3685346,https://doi.org/10.1145/3679318.3685346,"The use of social robots is gaining importance in various sectors, especially in public institutions, to counteract labor shortages. This article explores the impact of assigning different social roles (Entertainer, Caretaker, and Service Provider) to robots in public libraries on users’ expectations regarding personality, emotional expression, communication style, and design features. Participants took part in an online survey (N=85) and expressed their expectations regarding the personality and design of the robots. The research questions aim to uncover the influence of social roles on user expectations and preferences. The results indicate that users indeed have varied expectations depending on the robot’s social role, affecting perceived personality traits, emotional expression, and communication style. The study also addresses users’ expectations regarding design features such as movement patterns, voice, and eye color. The exploration of these complex interactions between robo-personalities, user expectations, and design provides valuable insights for the field of Human-Robot Interaction (HRI). The research contributes to the limited literature on the design of social robots for public spaces, emphasizing the importance of aligning robot personalities with user expectations to enhance acceptance and user satisfaction.",
10.1145/3706598.3713494,inproceedings,"Wang, Ge and Zhao, Jun and Van Kleek, Max and Pea, Roy and Shadbolt, Nigel",FamiData Hub: A Speculative Design Exploration with Families on Smart Home Datafication,2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3713494,https://doi.org/10.1145/3706598.3713494,"Smart home technologies are becoming increasingly common in households with children. While privacy and security concerns have been widely discussed, a critical issue often overlooked is the extensive data harvesting embedded in these smart homes and its manipulative impact on children through algorithmic decision-making. In this paper, we introduce FamiData Hub, a speculative prototype designed to empower families to navigate the datafication of smart homes. Through 17 study sessions—including speculative interviews followed by co-design activities—with 30 children and 25 parents, we found that families face challenges related to smart home datafication, such as the erosion of boundaries in family spaces, loss of control over family norms, and diminished autonomy in data-driven decision-making processes. Our findings offer key design recommendations for rethinking smart home technologies to better safeguard children’s data, advocating for respectful, family-centered approaches that challenge the normalization of datafication in domestic life.",
10.1145/3610977.3634979,inproceedings,"Hsu, Long-Jing and Stafford, Philip B. and Khoo, Weslie and Swaminathan, Manasi and Amon, Kyrie Jig and Sato, Hiroki and Tsui, Katherine M. and Crandall, David J. and Sabanovi\'{c}, Selma","""Give it Time:"" Longitudinal Panels Scaffold Older Adults' Learning and Robot Co-Design",2024,,Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610977.3634979,https://doi.org/10.1145/3610977.3634979,"Participatory robot design projects with older adults often use multiple sessions to encourage design feedback and active participation from users. Prior projects have, however, not analyzed the learning outcomes for older adults across co-design sessions and how they support constructive design feedback and meaningful participation. To bridge this gap, we examined the learning outcomes within a ""longitudinal panel."" This panel comprised seven co-design sessions with 11 older adults of varying cognitive abilities over six months, aimed at designing a robot to guide a photograph-based conversational activity. Using Nelson and Stolterman's framework of the hierarchy of design-learning, we demonstrate how older adult panelists achieved multiple design-learning outcomes- capacity, confidence, capability, competence, courage, and connection- which allowed them to provide actionable design suggestions. We provide guidelines for conducting longitudinal panels that can enhance user design-learning and participation in robot design.",283–292
10.1145/3603555.3608563,inproceedings,"Brauner, Philipp and Schmeckel, Tim and Vervier, Luisa and Liehner, Gian Luca and Ziefle, Martina",Using Commercial Children’s Smart Pens for Prototyping Interactive Science Communication Media in the Digital Transformation of Production,2023,,Proceedings of Mensch Und Computer 2023,10.1145/3603555.3608563,https://doi.org/10.1145/3603555.3608563,"The Tiptoi smart pen has a huge fan following among children and their parents. Interacting with the pen makes it easy to see why: the pen has been designed to help children learn and explore complex information about a vast array of topics, from farms to learning about the human body. This work examined whether the Tiptoi pen could be similarly used to communicate science to the general public, taking a research project on the digital transformation of production as an example. Following an iterative design approach, we created an interactive book that allows self-directed engagement with the general research motivation, partners, and objectives of the project. Building on a SWOT analysis, we conducted qualitative semi-structured interviews with four subjects to evaluate the prototype. The evaluation was generally positive. Participants recognized the playful and appealing design, and the vivid and tangible knowledge transfer as strengths but were unhappy with the pen’s toy-like appearance. They also identified potential functions such as real factory sounds and narrative techniques to enhance storytelling as opportunities and mobile learning apps and virtual reality applications as threats. The article concludes with alternative use cases for smart pens and actionable implementation guidelines.",341–348
10.1145/3706598.3713996,inproceedings,"Madill, Philippa and Newton, Matthew and Zhao, Huanjun and Lian, Yichen and McKendrick, Zachary and Finn, Patrick and Nittala, Aditya Shekhar and Sharlin, Ehud",Playing with Robots: Performing Arts Techniques for Designing and Understanding Robot Group Movement,2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3713996,https://doi.org/10.1145/3706598.3713996,"In this work, we introduce a formal design approach derived from the performing arts to design robot group behaviour. In our first experiment, we worked with professional actors, directors, and non-specialists using a participatory design approach to identify common group behaviour patterns. In a follow-up studio work, we identified twelve common group movement patterns, transposed them into a performance script, built a scale model to support the performance process, and evaluated the patterns with a senior actor under studio conditions. We evaluated our refined models with 20 volunteers in a user study in the third experiment. Results from our affective circumplex modelling suggest that the patterns elicit positive emotional responses from the users. Also, participants performed better than chance in identifying the motion patterns without prior training. Based on our results, we propose design guidelines for social robots’ behaviour and movement design to improve their overall comprehensibility in interaction.",
10.1145/3670653,proceedings,,MuC '24: Proceedings of Mensch und Computer 2024,2024,,,,,,
10.1145/3744169,proceedings,,AAR '25: Proceedings of the sixth decennial Aarhus conference: Computing X Crisis,2025,,,,,,
10.1145/3628516,proceedings,,IDC '24: Proceedings of the 23rd Annual ACM Interaction Design and Children Conference,2024,,,,,,
10.1145/3656650,proceedings,,AVI '24: Proceedings of the 2024 International Conference on Advanced Visual Interfaces,2024,,,,,"AVI 2024 is the 17th edition of the International Conference on Advanced Visual Interfaces, held in Arenzano, Genoa (IT), in cooperation with ACM, ACM SIGCHI, ACM SIGMM, and ACM SIGWEB.Every two years since 1992, AVI has gathered a vast international community of experts with a wide range of backgrounds. Throughout three decades, AVI has gained and holds a prestigious position among International HCI conferences, boasting a dedicated nucleus of returning participants, but also providing a venue for young researchers to show their achievements and establish contacts with senior community members.AVI 2024 presents a broad and sound scientific program covering traditional AVI topics on information and data visualization, interaction with multimodal user interfaces, augmented and virtual reality, while also addressing emerging topics including the application of generative artificial intelligence in HCI design and evaluation.The program features the presentation of 21 long research papers and 28 short papers selected through a rigorous double-blind reviewing process and organized into sessions on 13 main topics. Furthermore, it includes the presentation of 48 poster papers, 9 demo papers, and 11 doctoral consortium papers, selected through a single-blind reviewing process. Finally, the rich and vibrant program includes 3 keynote talks, 3 tutorials, and 10 workshops addressing some of the most exciting issues in HCI.Submissions to AVI 2024 came from 34 different countries distributed in descending order in Europe, Asia, North America, South America, and Africa.",
10.1145/3769854,article,"Giorgi, Ioanna and Rajapakse, Sachini and Palomino, Marco and Masala, Giovanni L",Older Adults’ Perceptions of Robots with Differing Intelligence in Social Multi-Robot Interactions,2025,J. Hum.-Robot Interact.,,10.1145/3769854,https://doi.org/10.1145/3769854,"Social robots present significant potential to support ageing societies, yet their integration into older adults’ lives still requires substantial investigation. Existing research has explored multiple factors that influence older adults’ attitudes towards robots, but few have directly manipulated perceptions of robot intelligence. We address this gap on the premise that older adults may experience reduced confidence in managing technology, making them more sensitive to cues of robot competence, as the basis for their trust and acceptance. This study adopts a human-multi-robot approach, situating social interactions within a group where human-robot and robot-robot interactions co-exist. Unlike research limited to dyadic interactions or that deploys multiple robots in isolation to provide complementary assistance or different points of engagement, we model group (triadic) interactions in a structured experiment where participants played a cognitive game simultaneously with two social robots of different cognitive competence. This design was intended to leverage inter-robot comparisons when forming older adults’ perceptions, rendering the manipulation of perceived intelligence more salient. Using a mixed-method approach, we explored how the intelligence construct affected trust, usability, and the willingness to adopt social robots, including preference for continued interaction. Our findings showed participants placed greater trust and intent to use the robot with higher constructed intelligence, though many favoured the robot that appealed to them aesthetically or displayed human-like fallibility, which some perceived as intelligence. The interaction increased participants' willingness to use robots in other proxy (sensitive, health-related) contexts, suggesting that perceptions formed in one context may transfer to others, potentially reinforcing acceptance of robots broadly with continued interactions.",
10.1145/3664968,proceedings,,MSIE '24: Proceedings of the 2024 6th International Conference on Management Science and Industrial Engineering,2024,,,,,,
10.1145/3550489,article,"Dennler, Nathaniel and Ruan, Changxiao and Hadiwijoyo, Jessica and Chen, Brenna and Nikolaidis, Stefanos and Matari\'{c}, Maja",Design Metaphors for Understanding User Expectations of Socially Interactive Robot Embodiments,2023,J. Hum.-Robot Interact.,,10.1145/3550489,https://doi.org/10.1145/3550489,"The physical design of a robot suggests expectations of that robot’s functionality for human users and collaborators. When those expectations align with the robot’s true capabilities, users are more likely to adopt the technologies for their intended use. However, the relationship between expectations and socially interactive robot design is not well understood. This article applies the concept of design metaphors to robot design and contributes the Metaphors for Understanding Functional and Social Anticipated Affordances dataset of 165 extant robots and the expectations users place on them. We used Mechanical Turk to crowd-source user expectation over three user studies. The first study (N = 382) associated crowd-sourced design metaphors to different robot embodiments. The second study (N = 803) assessed initial social expectations of robot embodiments. The final study (N = 805) addressed the degree of abstraction of the design metaphors and the functional expectations projected on robot embodiments. We performed analyses to gain insights into how design metaphors can be used to understand social and functional expectations of robots and how these data can be visualized to be useful for study designers and robot designers. Together, these results can serve to guide robot designers toward aligning user expectations with true robot capabilities, facilitating positive human–robot interaction.",
10.1145/3679318.3685335,inproceedings,"Sharma, Sumita and Howell, Noura and Vent\""{a}-Olkkonen, Leena and Iivari, Netta and Eden, Grace and Hartikainen, Heidi and Kinnula, Marianne and Durall, Eva and Nitsche, Michael and Okkonen, Jussi and Pait, Supratim and Rubegni, Elisa and Sluis-Thiescheffer, Wouter and van der Velden, Lonneke and Varanasi, Uttishta Sreerama",Promoting Criticality with Design Futuring with Young Children,2024,,Proceedings of the 13th Nordic Conference on Human-Computer Interaction,10.1145/3679318.3685335,https://doi.org/10.1145/3679318.3685335,"As children's everyday interaction with emerging technologies increases, they need to develop criticality to navigate ethical impacts of technology and when imagining futures with technology. We explore how design futuring can facilitate children's criticality through four different workshops with children from India, Finland, and the USA. Participants imagined futures with technologies while critically considering ethical impacts. In the findings, themes related to empowerment and ethics emerged in children's imagined futures. We discuss promoting criticality and empowerment with children's imagined futures, and how these futures can respond to diverse, local issues based on their lived experiences. Our work diversifies design research by highlighting local futures, and the criticality of those imagined futures, from children across the world.",
10.1145/3577190,proceedings,,ICMI '23: Proceedings of the 25th International Conference on Multimodal Interaction,2023,,,,,,
10.1145/3711609,proceedings,,ICICM '24: Proceedings of the 2024 14th International Conference on Information Communication and Management,2024,,,,,,
10.1145/3686215,proceedings,,ICMI '24 Companion: Companion Proceedings of the 26th International Conference on Multimodal Interaction,2024,,,,,,
10.1145/3568162.3576995,inproceedings,"Antony, Victor Nikhil and Cho, Sue Min and Huang, Chien-Ming","Co-Designing with Older Adults, for Older Adults: Robots to Promote Physical Activity",2023,,Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3568162.3576995,https://doi.org/10.1145/3568162.3576995,"Lack of physical activity has severe negative health consequences for older adults and limits their ability to live independently. Robots have been proposed to help engage older adults in physical activity (PA), albeit with limited success. There is a lack of robust understanding of older adults' needs and wants from robots designed to engage them in PA. In this paper, we report on the findings of a co-design process where older adults, physical therapy experts, and engineers designed robots to promote PA in older adults. We found a variety of motivators for and barriers against PA in older adults; we, then, conceptualized a broad spectrum of possible robotic support and found that robots can play various roles to help older adults engage in PA. This exploratory study elucidated several overarching themes and emphasized the need for personalization and adaptability. This work highlights key design features that researchers and engineers should consider when developing robots to engage older adults in PA, and underscores the importance of involving various stakeholders in the design and development of assistive robots.",506–515
10.1145/3582515,proceedings,,GoodIT '23: Proceedings of the 2023 ACM Conference on Information Technology for Social Good,2023,,,,,,
10.1145/3672539,proceedings,,UIST Adjunct '24: Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology,2024,,,,,,
10.1145/3711057,article,"Bhattacharjee, Ananya and Rifat, Mohammad Rashidujjaman and Das, Dipto and Haque, S M Taiabul and Ahmed, Syed Ishtiaque",Residual Mobilities and Religious Practices: Exploring the Experiences of the Hindu Migrants in Canada,2025,Proc. ACM Hum.-Comput. Interact.,,10.1145/3711057,https://doi.org/10.1145/3711057,"Informed by the previous HCI and CSCW scholarship on residual mobility -- a concept that transcends mere geographical relocation to encompass socio-cultural and communal disruptions -- this study probes the unique religious and spiritual challenges faced by the Hindu migrants from the Indian subcontinent in Canada. Through interviews with 20 participants, we investigate the role of technology in navigating a diverse religious landscape in professional environments, coping with changing religious materiality, and passing down traditions to the next generation. Our work identifies the community's proactive use of social media and videoconferencing for religious festivals and connection with their religious community. The findings raise several implications for CSCW research on supporting residual mobility experiences of the Hindu migrants, including effective organization of religious event information, virtual support for material aspects of religious rituals, and fostering online environments that enable pluralistic spiritual engagement.",
10.1145/3613905,proceedings,,CHI EA '24: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2024,,,,,,
10.1145/3613904.3642840,inproceedings,"Liu, Zihan and Li, Han and Chen, Anfan and Zhang, Renwen and Lee, Yi-Chieh",Understanding Public Perceptions of AI Conversational Agents: A Cross-Cultural Analysis,2024,,Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,10.1145/3613904.3642840,https://doi.org/10.1145/3613904.3642840,"Conversational Agents (CAs) have increasingly been integrated into everyday life, sparking significant discussions on social media. While previous research has examined public perceptions of AI in general, there is a notable lack in research focused on CAs, with fewer investigations into cultural variations in CA perceptions. To address this gap, this study used computational methods to analyze about one million social media discussions surrounding CAs and compared people’s discourses and perceptions of CAs in the US and China. We find Chinese participants tended to view CAs hedonically, perceived voice-based and physically embodied CAs as warmer and more competent, and generally expressed positive emotions. In contrat, US participants saw CAs more functionally, with an ambivalent attitude. Warm perception was a key driver of positive emotions toward CAs in both countries. We discussed practical implications for designing contextually sensitive and user-centric CAs to resonate with various users’ preferences and needs.",
10.1145/3672277,article,"Antony, Victor Nikhil and Huang, Chien-Ming",ID.8: Co-Creating Visual Stories with Generative AI,2024,ACM Trans. Interact. Intell. Syst.,,10.1145/3672277,https://doi.org/10.1145/3672277,"Storytelling is an integral part of human culture and significantly impacts cognitive and socio-emotional development and connection. Despite the importance of interactive visual storytelling, the process of creating such content requires specialized skills and is labor-intensive. This article introduces ID.8, an open-source system designed for the co-creation of visual stories with generative AI. We focus on enabling an inclusive storytelling experience by simplifying the content creation process and allowing for customization. Our user evaluation confirms a generally positive user experience in domains such as enjoyment and exploration while highlighting areas for improvement, particularly in immersiveness, alignment, and partnership between the user and the AI system. Overall, our findings indicate promising possibilities for empowering people to create visual stories with generative AI. This work contributes a novel content authoring system, ID.8, and insights into the challenges and potential of using generative AI for multimedia content creation.",
10.1145/3631700,proceedings,,"UMAP Adjunct '24: Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,,,,,,
10.1145/3637843,proceedings,,ICRAI '23: Proceedings of the 2023 9th International Conference on Robotics and Artificial Intelligence,2023,,,,,,
10.1145/3610977.3634948,inproceedings,"Axelsson, Minja and Spitale, Micol and Gunes, Hatice","""Oh, Sorry, I Think I Interrupted You"": Designing Repair Strategies for Robotic Longitudinal Well-being Coaching",2024,,Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,10.1145/3610977.3634948,https://doi.org/10.1145/3610977.3634948,"Robotic well-being coaches have been shown to successfully promote people's mental well-being. To provide successful coaching, a robotic coach should have the capability to repair the mistakes it makes. Past investigations of robot mistakes are limited to game or task-based, one-off and in-lab studies. This paper presents a 4-phase design process to design repair strategies for robotic longitudinal well-being coaching with the involvement of real-world stakeholders: 1) designing repair strategies with a professional well-being coach; 2) a longitudinal study with the involvement of experienced users (i.e., who had already interacted with a robotic coach) to investigate the repair strategies defined in (1); 3) a design workshop with users from the study in (2) to gather their perspectives on the robotic coach's repair strategies; 4) discussing the results obtained in (2) and (3) with the mental well-being professional to reflect on how to design repair strategies for robotic coaching. Our results show that users have different expectations for a robotic coach than a human coach, which influences how repair strategies should be designed. We show that different repair strategies (e.g., apologizing, explaining, or repairing empathically) are appropriate in different scenarios, and that preferences for repair strategies change during longitudinal interactions with the robotic coach.",13–22
10.1145/3742800,proceedings,,C&amp;T '25: Proceedings of the 12th International Conference on Communities &amp; Technologies,2025,,,,,,
10.1145/3713043,proceedings,,IDC '25: Proceedings of the 24th Interaction Design and Children,2025,,,,,,
10.1145/3570945,proceedings,,IVA '23: Proceedings of the 23rd ACM International Conference on Intelligent Virtual Agents,2023,,,,,"This volume contains the papers presented at the 23nd International Conference on Intelligent Virtual Agents (IVA 2023) located in W\""{u}rzburg, Germany, from 19. to 22.09.2023.",
10.1145/3580252,proceedings,,"CHASE '23: Proceedings of the 8th ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies",2023,,,,,"It is our great pleasure to welcome you to the eighth edition of the IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE 2023). This is a leading international conference in the field of connected health, an interdisciplinary area with rich research problems and opportunities. CHASE aims to bring together researchers working in the smart and connected health area around the world to exchange ideas and foster collaborations. Its scope covers sensing, communications, and intelligent analytics in support of health-related applications, systems, and engineering technologies. The innovative works published at CHASE will revolutionize preventative health and personalized medicine, providing rich medical information never-before available to individuals while driving down healthcare costs.",
10.1145/3544549,proceedings,,CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems,2023,,,,,,
10.1145/3719384,proceedings,,AICCC '24: Proceedings of the 2024 7th Artificial Intelligence and Cloud Computing Conference,2024,,,,,,
10.1145/3659110,article,"Ayub, Ali and De Francesco, Zachary and Mehta, Jainish and Yaakoub Agha, Khaled and Holthaus, Patrick and Nehaniv, Chrystopher L. and Dautenhahn, Kerstin","A Human-Centered View of Continual Learning: Understanding Interactions, Teaching Patterns, and Perceptions of Human Users Toward a Continual Learning Robot in Repeated Interactions",2024,J. Hum.-Robot Interact.,,10.1145/3659110,https://doi.org/10.1145/3659110,"Continual learning (CL) has emerged as an important avenue of research in recent years, at the intersection of Machine Learning (ML) and Human–Robot Interaction (HRI), to allow robots to continually learn in their environments over long-term interactions with humans. Most research in CL, however, has been robot-centered to develop CL algorithms that can quickly learn new information on systematically collected static datasets. In this article, we take a human-centered approach to CL, to understand how humans interact with, teach, and perceive CL robots over the long term, and if there are variations in their teaching styles. We developed a socially guided CL system that integrates CL models for object recognition with a mobile manipulator robot and allows humans to directly teach and test the robot in real time over multiple sessions. We conducted an in-person study with 60 participants who interacted with the CL robot in 300 sessions with 5 sessions per participant. In this between-participant study, we used three different CL models deployed on a mobile manipulator robot. An extensive qualitative and quantitative analysis of the data collected in the study shows that there is significant variation among the teaching styles of individual users indicating the need for personalized adaptation to their distinct teaching styles. Our analysis shows that the constrained experimental setups that have been widely used to test most CL models are not adequate, as real users interact with and teach CL robots in a variety of ways. Finally, our analysis shows that although users have concerns about CL robots being deployed in our daily lives, they mention that with further improvements CL robots could assist older adults and people with disabilities in their homes.",
10.1145/3603178.3603185,inbook,,Working with Algorithms,2023,,From Algorithms to Thinking Machines: The New Digital Power,,https://doi.org/10.1145/3603178.3603185,"This book introduces and provides an analysis of the basic concepts of algorithms, data, and computation and discusses the role of algorithms in ruling and shaping our world. It provides a clear understanding of the power and impact on humanity of the pervasive use of algorithms.From Algorithms to Thinking Machines combines a layman’s approach with a well-founded scientific description to discuss both principles and applications of algorithms, Big Data, and machine intelligence. The book provides a clear and deep description of algorithms, software systems, data-driven applications, machine learning, and data science concepts, as well as the evolution and impact of artificial intelligence.After introducing computing concepts, the book examines the relationships between algorithms and human work, discussing how jobs are being affected and how computers and software programs are influencing human life and the labor sphere. Topics such as value alignment, collective intelligence, Big Data impact, automatic decision methods, social control, and political uses of algorithms are illustrated and discussed at length without excessive technical detail. Issues related to how corporations, governments, and autocratic regimes are exploiting algorithms and machine intelligence methods to influence people, laws, and markets are extensively addressed. Ethics principles in software programming and human value insertion into artificial intelligence algorithms are also discussed.",
10.1145/3544548.3581340,inproceedings,"Kim, Taenyun and Molina, Maria D. and Rheu, Minjin (MJ) and Zhan, Emily S. and Peng, Wei",One AI Does Not Fit All: A Cluster Analysis of the Laypeople’s Perception of AI Roles,2023,,Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,10.1145/3544548.3581340,https://doi.org/10.1145/3544548.3581340,"Artificial intelligence (AI) applications have become an integral part of our society. However, studying AI as one entity or studying idiosyncratic applications separately both have limitations. Thus, this study used computational methods to categorize ten different AI roles prevalent in our everyday life and compared laypeople’s perceptions of them using online survey data (N = 727). Based on theoretical factors related to the fundamental nature of AI, the principal component analysis revealed two dimensions that categorize AI: human involvement and AI autonomy. K-means clustering identified four AI role clusters: tools (low in both dimensions), servants (high human involvement and low AI autonomy), assistants (low human involvement and high AI autonomy), and mediators (high in both dimensions). Multivariate analyses of covariances revealed that people assessed AI mediators the most and AI tools the least favorably. Demographics also influenced laypeople’s assessments of AI. The implications of these results are discussed.",
10.1145/3656156,proceedings,,DIS '24 Companion: Companion Publication of the 2024 ACM Designing Interactive Systems Conference,2024,,,,,,
10.1145/3731867,proceedings,,"CIoTSC '24: Proceedings of the 2024 2nd International Conference on Computer, Internet of Things and Smart City",2024,,,,,,
10.1145/3544548.3581167,inproceedings,"Windl, Maximiliane and Schmidt, Albrecht and Feger, Sebastian S.",Investigating Tangible Privacy-Preserving Mechanisms for Future Smart Homes,2023,,Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,10.1145/3544548.3581167,https://doi.org/10.1145/3544548.3581167,"Most smart home devices have multiple sensors, such as cameras and microphones; however, most cannot be controlled individually. Tangible privacy mechanisms provide control over individual sensors and instill high certainty of privacy. Yet, it remains unclear how they can be used in future smart homes. We conducted three studies to understand how tangible privacy mechanisms scale across multiple devices and respond to user needs. First, we conducted a focus group (N=8) on speculative tangible control artifacts to understand the user perspective. Second, we ran a workshop at a human-computer interaction conference (N=8) on tangible privacy. Third, we conducted a six-week in-the-wild study with a tangible, static privacy dashboard across six households. Our findings help to contrast the need for tangible privacy mechanisms on the sensor level with user needs on a smart home level. Finally, we discuss our design implications for future smart homes through the lens of inclusive privacy.",
10.1145/3563702,article,"Mollen, Joost and van der Putten, Peter and Darling, Kate",Bonding with a Couchsurfing Robot: The Impact of Common Locus on Human-Robot Bonding In-the-Wild,2023,J. Hum.-Robot Interact.,,10.1145/3563702,https://doi.org/10.1145/3563702,"Due to an increased presence of robots in human-inhabited environments, we observe a growing body of examples in which humans show behavior that is indicative of strong social engagement towards robots that do not possess any life-like realism in appearance or behavior. In response, we focus on the under-explored concept of a common locus as a relevant driver for a robot passing a social threshold. The key principle of common locus is that sharing place and time with a robotic artifact functions as an important catalyst for a perception of shared experiences, which in turn leads to bonding. We present BlockBots, minimal cube-shaped robotic artifacts that are deployed in an unsupervised, open-ended and in-the-field experimental setting aimed to explore the relevance of this concept. Participants host the BlockBot in their domestic environment before passing it on, without necessarily knowing they are taking part in an experiment. Qualitative data suggest that participants make identity and mind attributions to the BlockBot. People that actively maintain a common locus with BlockBot by taking it with them when changing location, on trips and during outdoor activities, project more of these attributes than others.",
10.1145/3716553,proceedings,,ICMI '25: Proceedings of the 27th International Conference on Multimodal Interaction,2025,,,,,,
10.1145/3677045,proceedings,,NordiCHI '24 Adjunct: Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction,2024,,,,,,
10.1145/3733155,proceedings,,PETRA '25: Proceedings of the 18th ACM International Conference on PErvasive Technologies Related to Assistive Environments,2025,,,,,,
10.1145/3746059,proceedings,,UIST '25: Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology,2025,,,,,,
10.1145/3624486,proceedings,,"eSAAM '23: Proceedings of the 3rd Eclipse Security, AI, Architecture and Modelling Conference on Cloud to Edge Continuum",2023,,,,,,
10.1145/3613904.3642852,inproceedings,"Liu, Di and Zhou, Hanqing and An, Pengcheng","""When He Feels Cold, He Goes to the Seahorse""—Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy",2024,,Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,10.1145/3613904.3642852,https://doi.org/10.1145/3613904.3642852,"Storymaking, as an integrative form of expressive arts therapy, is an effective means to foster family communication. Yet, the integration of generative AI as expressive materials in therapeutic storymaking remains underexplored. And there is a lack of HCI implications on how to support families and therapists in this context. Addressing this, our study involved five weeks of storymaking sessions with seven families guided by a professional therapist. In these sessions, the families used both traditional art-making materials and image-based generative AI to create and evolve their family stories. Via the rich empirical data and commentaries from four expert therapists, we contextualize how families creatively melded AI and traditional expressive materials to externalize their ideas and feelings. Through the lens of Expressive Therapies Continuum (ETC), we characterize the therapeutic implications of AI as expressive materials. Desirable interaction qualities to support children, parents, and therapists are distilled for future HCI research.",
10.1145/3663548.3675651,inproceedings,"Le, Lindy","""I Am Human, Just Like You"": What Intersectional, Neurodivergent Lived Experiences Bring to Accessibility Research",2024,,Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility,10.1145/3663548.3675651,https://doi.org/10.1145/3663548.3675651,"The increasing prevalence of neurodivergence has led society to give greater recognition to the importance of neurodiversity. Yet societal perceptions of neurodivergence continue to be predominantly negative. Drawing on Critical Disability Studies, accessibility researchers have demonstrated how neuronormative assumptions dominate HCI. Despite their guidance, neurodivergent and disabled individuals are still marginalized in technology research. In particular, intersectional identities remain largely absent from HCI neurodivergence research. In this paper, I share my perspective as an outsider of the academic research community: I use critical autoethnography to analyze my experiences of coming to understand, accept, and value my neurodivergence within systems of power, privilege, and oppression. Using Data Feminism as an accessible and practical guide to intersectionality, I derive three tenets for reconceptualizing neurodivergence to be more inclusive of intersectional experiences: (1) neurodivergence is a functional difference, not a deficit; (2) neurodivergent disability is a moment of friction, not a static label; and (3) neurodivergence accessibility is a collaborative practice, not a one-sided solution. Then, I discuss the tenets in the context of existing HCI research, applying the same intersectional lens. Finally, I offer three suggestions for how accessibility research can apply these tenets in future work, to bridge the gap between accessibility theory and practice in HCI neurodivergence research.",
10.1145/3706370,proceedings,,IMX '25: Proceedings of the 2025 ACM International Conference on Interactive Media Experiences,2025,,,,,,
10.1145/3583961,proceedings,,IHM '23: Proceedings of the 34th Conference on l'Interaction Humain-Machine,2023,,,,,,
10.1145/3719160,proceedings,,CUI '25: Proceedings of the 7th ACM Conference on Conversational User Interfaces,2025,,,,,,
10.1145/3723178,proceedings,,ICCA '24: Proceedings of the 3rd International Conference on Computing Advancements,2024,,,,,,
10.1613/jair.1.16882,article,"Chen, Jennifer J.","A Scoping Study on AI Affordances in Early Childhood Education: Mapping the Global Landscape, Identifying Research Gaps, and  Charting Future Research Directions",2025,J. Artif. Int. Res.,,10.1613/jair.1.16882,https://doi.org/10.1613/jair.1.16882,"Artificial intelligence (AI), manifested in the forms of technologies, systems, tools, and applications, has advanced rapidly, especially in recent years. It has permeated many aspects of human behavior and nearly all sectors of society, such as healthcare and education. In the context of early childhood education (ECE), AI has afforded valuable opportunities that directly and indirectly enhance children’s learning and development. While there are already two existing reviews of the literature on AI in ECE, they show either a lack of descriptive information concerning selected studies or inconsistencies between inclusion/exclusion criteria and selected studies, thereby raising concerns about their rigor. Representing a more methodologically rigorous effort and a significant contribution to the field of AI in ECE, this scoping study aimed to achieve three main goals: (1) “mapping” the global landscape of the current extent, range, and nature of relevant studies on the affordances of AI for use in ECE, (2) identifying potential research gaps, and (3) charting future research directions. Specifically, it addressed this overarching research question: What is the global landscape of the current state of knowledge concerning the affordances of AI for use in ECE? Specifically, the state of knowledge here refers to three aspects: (1) extent, (2) range, and (3) nature. First, regarding the extent aspect, the empirical knowledge was derived from 18 research articles in 11 countries and 16 peer-reviewed academic journals between 2005 and 2023, with 14 of these articles published in the past four years (2020–2023). Second, with respect to the range of study populations, it covered 15,081 children in early childhood (ages 2 to 8 years) across these 11 countries. Third, thematic analysis of these studies revealed four areas of AI affordances: (1) AI as tangible and intangible tools for interactive learning and information retrieval, (2) AI as technology for predicting/classifying children’s conditions, (3) AI as the object for learning by adapting to and personalizing children’s learning, and (4) AI as the subject for children's learning about it. Based on these findings, this scoping review identified three research gaps for future studies: (1) interviewing and/or surveying education stakeholders (parents, educators, policymakers) to explore the affordances of appropriate AI for use with, by, and for children bearing ethical considerations; (2) conducting group comparisons to investigate contextual factors contributing to the “AI divide” among children from different socioeconomic backgrounds; and (3) comparing sociocultural influences on AI use in ECE across cultures.",
10.1145/3652037,proceedings,,PETRA '24: Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments,2024,,,,,,
10.1145/3593434,proceedings,,EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering,2023,,,,,,
10.1145/3686038,proceedings,,TAS '24: Proceedings of the Second International Symposium on Trustworthy Autonomous Systems,2024,,,,,,
10.1145/3673805,proceedings,,ECCE '24: Proceedings of the European Conference on Cognitive Ergonomics 2024,2024,,,,,,
10.1145/3584376,proceedings,,"RICAI '22: Proceedings of the 2022 4th International Conference on Robotics, Intelligent Control and Artificial Intelligence",2022,,,,,,
10.1145/3656374,article,"Kucherenko *, Taras and Wolfert *, Pieter and Yoon *, Youngwoo and Viegas, Carla and Nikolov, Teodor and Tsakov, Mihail and Henter, Gustav Eje",Evaluating Gesture Generation in a Large-scale Open Challenge: The GENEA Challenge 2022,2024,ACM Trans. Graph.,,10.1145/3656374,https://doi.org/10.1145/3656374,"This article reports on the second GENEA Challenge to benchmark data-driven automatic co-speech gesture generation. Participating teams used the same speech and motion dataset to build gesture-generation systems. Motion generated by all these systems was rendered to video using a standardised visualisation pipeline and evaluated in several large, crowdsourced user studies. Unlike when comparing different research articles, differences in results are here only due to differences between methods, enabling direct comparison between systems. The dataset was based on 18 hours of full-body motion capture, including fingers, of different persons engaging in a dyadic conversation. Ten teams participated in the challenge across two tiers: full-body and upper-body gesticulation. For each tier, we evaluated both the human-likeness of the gesture motion and its appropriateness for the specific speech signal. Our evaluations decouple human-likeness from gesture appropriateness, which has been a difficult problem in the field.The evaluation results show some synthetic gesture conditions being rated as significantly more human-like than 3D human motion capture. To the best of our knowledge, this has not been demonstrated before. On the other hand, all synthetic motion is found to be vastly less appropriate for the speech than the original motion-capture recordings. We also find that conventional objective metrics do not correlate well with subjective human-likeness ratings in this large evaluation. The one exception is the Fr\'{e}chet gesture distance (FGD), which achieves a Kendall’s tau rank correlation of around -0.5. Based on the challenge results we formulate numerous recommendations for system building and evaluation.",
10.1145/3689050,proceedings,,"TEI '25: Proceedings of the Nineteenth International Conference on Tangible, Embedded, and Embodied Interaction",2025,,,,,,
10.1145/3658852,proceedings,,MOCO '24: Proceedings of the 9th International Conference on Movement and Computing,2024,,,,,,
10.1145/3702468,proceedings,,ICRSA '24: Proceedings of the 2024 7th International Conference on Robot Systems and Applications,2024,,,,,,
10.1145/3590837,proceedings,,ICIMMI '22: Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence,2022,,,,,,
10.1145/3644815,proceedings,,CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI,2024,,,,,"The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.",
10.1145/3641554,proceedings,,SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,,,,,"Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the ""Steel City"" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is ""Leading the Transformation"". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.",
10.1145/3544548.3581296,inproceedings,"Scott, Ava Elizabeth and Neumann, Daniel and Niess, Jasmin and Wo\'{z}niak, Pawe\l{} W.",Do You Mind? User Perceptions of Machine Consciousness,2023,,Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,10.1145/3544548.3581296,https://doi.org/10.1145/3544548.3581296,"The prospect of machine consciousness cultivates controversy across media, academia, and industry. Assessing whether non-experts perceive technologies as conscious, and exploring the consequences of this perception, are yet unaddressed challenges in Human Computer Interaction (HCI). To address them, we surveyed 100 people, exploring their conceptualisations of consciousness and if and how they perceive consciousness in currently available interactive technologies. We show that many people already perceive a degree of consciousness in GPT-3, a voice chat bot, and a robot vacuum cleaner. Within participant responses we identified dynamic tensions between denial and speculation, thinking and feeling, interaction and experience, control and independence, and rigidity and spontaneity. These tensions can inform future research into perceptions of machine consciousness and the challenges it represents for HCI. With both empirical and theoretical contributions, this paper emphasises the importance of HCI in an era of machine consciousness, real, perceived or denied.",
10.1145/3610419,proceedings,,AIR '23: Proceedings of the 2023 6th International Conference on Advances in Robotics,2023,,,,,,
10.1145/3544548.3580799,inproceedings,"Zhou, Ran and Schwemler, Zachary and Baweja, Akshay and Sareen, Harpreet and Hunt, Casey Lee and Leithinger, Daniel",TactorBots: A Haptic Design Toolkit for Out-of-lab Exploration of Emotional Robotic Touch,2023,,Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,10.1145/3544548.3580799,https://doi.org/10.1145/3544548.3580799,"Emerging research has demonstrated the viability of emotional communication through haptic technology inspired by interpersonal touch. However, the meaning-making of artificial touch remains ambiguous and contextual. We see this ambiguity caused by robotic touch’s ""otherness"" as an opportunity for exploring alternatives. To empower emotional haptic design in longitudinal out-of-lab exploration, we devise TactorBots, a design toolkit consisting of eight wearable hardware modules for rendering robotic touch gestures controlled by a web-based software application. We deployed TactorBots to thirteen designers and researchers to validate its functionality, characterize its design experience, and analyze what, how, and why alternative perceptions, practices, contexts, and metaphors would emerge in the experiment. We provide suggestions for designing future toolkits and field studies based on our experiences. Reflecting on the findings, we derive design implications for further enhancing the ambiguity and shifting the mindsets to expand the design space.",
10.1145/3627050,proceedings,,IoT '23: Proceedings of the 13th International Conference on the Internet of Things,2023,,,,,,
10.1145/3605390,proceedings,,CHItaly '23: Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter,2023,,,,,,
10.1145/3698061,proceedings,,C&amp;C '25: Proceedings of the 2025 Conference on Creativity and Cognition,2025,,,,,,
10.1145/3663547,proceedings,,ASSETS '25: Proceedings of the 27th International ACM SIGACCESS Conference on Computers and Accessibility,2025,,,,,,
10.1145/3647444,proceedings,,ICIMMI '23: Proceedings of the 5th International Conference on Information Management &amp; Machine Intelligence,2023,,,,,,
10.1145/3674912,proceedings,,CompSysTech '24: Proceedings of the International Conference on Computer Systems and Technologies 2024,2024,,,,,,
10.1145/3679318,proceedings,,NordiCHI '24: Proceedings of the 13th Nordic Conference on Human-Computer Interaction,2024,,,,,,
10.1145/3717511,proceedings,,IVA '25: Proceedings of the 25th ACM International Conference on Intelligent Virtual Agents,2025,,,,,,
10.1145/3747327,proceedings,,ICMI '25 Companion: Companion Proceedings of the 27th International Conference on Multimodal Interaction,2025,,,,,,
10.1145/3749012,proceedings,,CHIGreece '25: Proceedings of the 3rd International Conference of the ACM Greek SIGCHI Chapter,2025,,,,,,
10.1145/3597512,proceedings,,TAS '23: Proceedings of the First International Symposium on Trustworthy Autonomous Systems,2023,,,,,,
10.1145/3759355,proceedings,,IntRob '25: Proceedings of the Intelligent Robotics FAIR 2025,2025,,,,,,
10.1145/3586182,proceedings,,UIST '23 Adjunct: Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,2023,,,,,,
10.1145/3715669,proceedings,,ETRA '25: Proceedings of the 2025 Symposium on Eye Tracking Research and Applications,2025,,,,,,
10.1145/3649921,proceedings,,FDG '24: Proceedings of the 19th International Conference on the Foundations of Digital Games,2024,,,,,,
10.1145/3628096,proceedings,,AfriCHI '23: Proceedings of the 4th African Human Computer Interaction Conference,2023,,,,,,
10.1145/3709026,proceedings,,CSAI '24: Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence,2024,,,,,,
10.1145/3604321,proceedings,,IMXw '23: Proceedings of the 2023 ACM International Conference on Interactive Media Experiences Workshops,2023,,,,,,
10.1145/3685073,proceedings,,"RCVE '24: Proceedings of the 2024 2nd International Conference on Robotics, Control and Vision Engineering",2024,,,,,,
10.1145/3610661,proceedings,,ICMI '23 Companion: Companion Publication of the 25th International Conference on Multimodal Interaction,2023,,,,,,
10.1145/3712623,proceedings,,AAIA '24: Proceedings of the 2024 2nd International Conference on Advances in Artificial Intelligence and Applications,2024,,,,,,
10.1145/3664476,proceedings,,"ARES '24: Proceedings of the 19th International Conference on Availability, Reliability and Security",2024,,,,,,
10.1145/3640544,proceedings,,IUI '24 Companion: Companion Proceedings of the 29th International Conference on Intelligent User Interfaces,2024,,,,,,
10.1145/3663548,proceedings,,ASSETS '24: Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility,2024,,,,,,
10.1145/3715275,proceedings,,"FAccT '25: Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency",2025,,,,,,
10.1145/3708359,proceedings,,IUI '25: Proceedings of the 30th International Conference on Intelligent User Interfaces,2025,,,,,,
10.1145/3715668,proceedings,,DIS '25 Companion: Companion Publication of the 2025 ACM Designing Interactive Systems Conference,2025,,,,,,
10.5555/3643142,proceedings,,WSC '23: Proceedings of the Winter Simulation Conference,2023,,,,,,
10.1145/3664934,proceedings,,ICIEI '24: Proceedings of the 2024 9th International Conference on Information and Education Innovations,2024,,,,,,
10.1145/3613904,proceedings,,CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,,,,,,
10.1145/3665689,proceedings,,BIC '24: Proceedings of the 2024 4th International Conference on Bioinformatics and Intelligent Computing,2024,,,,,,
10.1145/3758871,proceedings,,CHCHI '24: Proceedings of the Twelfth International Symposium of Chinese CHI,2024,,,,,,
10.1145/3615335,proceedings,,SIGDOC '23: Proceedings of the 41st ACM International Conference on Design of Communication,2023,,,,,,
10.1145/3675417,proceedings,,DEAI '24: Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence,2024,,,,,,
10.1145/3699682,proceedings,,"UMAP '25: Proceedings of the 33rd ACM Conference on User Modeling, Adaptation and Personalization",2025,,,,,,
10.1145/3591196,proceedings,,C&amp;C '23: Proceedings of the 15th Conference on Creativity and Cognition,2023,,,,,,
10.1145/3640794,proceedings,,CUI '24: Proceedings of the 6th ACM Conference on Conversational User Interfaces,2024,,,,,,
10.5555/3635637,proceedings,,AAMAS '24: Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems,2024,,,,,"Welcome to AAMAS-2024, the 23th edition of the International Conference on Autonomous Agents and Multiagent Systems!AAMAS is the largest and most influential conference in the area of agents and multiagent systems, bringing together researchers and practitioners in all areas of agent technology and providing an internationally renowned high-profile forum for publishing and finding out about the latest developments in the field. AAMAS is the flagship conference of the non-profit International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS).After two attempts to hold AAMAS in New Zealand for the first time, which were forced online by the COVID19 pandemic, we are happy that the 2024 edition finally comes to Auckland, New Zealand. Previous editions were held in Bologna (2002), Melbourne (2003), New York (2004), Utrecht (2005), Hakodate (2006), Honolulu (2007), Estoril (2008), Budapest (2009), Toronto (2010), Taipei (2011), Valencia (2012), Saint Paul (2013), Paris (2014), Istanbul (2015), Singapore (2016), Sao Paulo (2017), Stockholm (2018), Montreal (2019), Auckland/online (2020), London/online (2021), Auckland/online (2022), and London (2023).",
10.1145/3757940,proceedings,,ICCIR '25: Proceedings of the 2025 5th International Conference on Control and Intelligent Robotics,2025,,,,,,
10.1145/3594315,proceedings,,ICCAI '23: Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence,2023,,,,,,
10.1145/3544548,proceedings,,CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,2023,,,,,,
10.1145/3641825,proceedings,,VRST '24: Proceedings of the 30th ACM Symposium on Virtual Reality Software and Technology,2024,,,,,,
10.1145/3584931,proceedings,,CSCW '23 Companion: Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing,2023,,,,,,
10.1145/3643663,proceedings,,RoSE '24: Proceedings of the 2024 ACM/IEEE 6th International Workshop on Robotics Software Engineering,2024,,,,,"Software engineering is a crucial enabler for successful deployment of robotic applications. However, much of the research that is advancing the state of the art in robotics software engineering is dispersed across numerous conferences that are either primarily attended by robotics researchers and practitioners (e.g., ICRA, IROS, SIMPAR) or attended mostly by software engineering researchers and practitioners (e.g., ICSE, FSE, MODELS). At robotics conferences, software engineering lacks visibility and vice versa.RoSE brings together researchers and practitioners from both domains at a prominent conference to foster crossfertilization between the two domains. Through a combination of presentations, papers, and discussions, RoSE helps researchers within the budding field of robotics software engineering to learn more about the challenges faced by robotics practitioners that (i) require further research from the software engineering community or (ii) are already solved but solutions have not yet been widely adopted by practitioners.",
10.1145/3702038,proceedings,,IHC '24: Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems,2024,,,,,,
10.1145/3603178,book,"Talia, Domenico",From Algorithms to Thinking Machines: The New Digital Power,2023,,,,,"This book introduces and provides an analysis of the basic concepts of algorithms, data, and computation and discusses the role of algorithms in ruling and shaping our world. It provides a clear understanding of the power and impact on humanity of the pervasive use of algorithms.From Algorithms to Thinking Machines combines a layman’s approach with a well-founded scientific description to discuss both principles and applications of algorithms, Big Data, and machine intelligence. The book provides a clear and deep description of algorithms, software systems, data-driven applications, machine learning, and data science concepts, as well as the evolution and impact of artificial intelligence.After introducing computing concepts, the book examines the relationships between algorithms and human work, discussing how jobs are being affected and how computers and software programs are influencing human life and the labor sphere. Topics such as value alignment, collective intelligence, Big Data impact, automatic decision methods, social control, and political uses of algorithms are illustrated and discussed at length without excessive technical detail. Issues related to how corporations, governments, and autocratic regimes are exploiting algorithms and machine intelligence methods to influence people, laws, and markets are extensively addressed. Ethics principles in software programming and human value insertion into artificial intelligence algorithms are also discussed.",
10.1145/3616961,proceedings,,Mindtrek '23: Proceedings of the 26th International Academic Mindtrek Conference,2023,,,,,,
10.1145/3707640,proceedings,,CHIWORK '25 Adjunct: Adjunct Proceedings of the 4th Annual Symposium on Human-Computer Interaction for Work,2025,,,,,"Welcome to CHIWORK 2025, the 4th Annual Symposium on Human-Computer Interaction for Work to be held at Centrum Wiskunde &amp; Informatica (CWI) in Amsterdam, The Netherlands.CHIWORK is the annual symposium that aims to grow our understanding of how Human-Computer Interaction (HCI) will support work in the future. Advances in Computing technology are rapidly changing the way we work. Human-computer interaction (HCI) is a critical aspect of this ongoing change, as a way to support workers in successfully navigating fast-paced changes in working environments, which might include novel computing devices, new sensing and work(er) wellbeing and performance measurement techniques, interacting with AI agents, and the new roles for people in work environments where automation is increasing.",
10.1145/3571884,proceedings,,CUI '23: Proceedings of the 5th International Conference on Conversational User Interfaces,2023,,,,,,
10.1145/3727648,proceedings,,"CAICE '25: Proceedings of the 4th International Conference on Computer, Artificial Intelligence and Control Engineering",2025,,,,,,
10.1145/3629606,proceedings,,CHCHI '23: Proceedings of the Eleventh International Symposium of Chinese CHI,2023,,,,,,
10.1145/3615522,proceedings,,VINCI '23: Proceedings of the 16th International Symposium on Visual Information Communication and Interaction,2023,,,,,,
10.5555/3715674,proceedings,,"SC-W '24: Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis",2024,,,,,,
10.1145/3643691,proceedings,,RAIE '24: Proceedings of the 2nd International Workshop on Responsible AI Engineering,2024,,,,,"RAIE'24 provides a platform for researchers, innovators, and industry leaders to exchange insights on the current and future landscape of responsible AI engineering. The workshop aims to foster interdisciplinary collaboration, bringing together professionals from fields like software engineering, AI, and social science. Our goal is to address the comprehensive challenges of developing AI systems responsibly and to inspire an increasing number of researchers to contribute to this vital field.",
10.1145/3704137,proceedings,,ICAAI '24: Proceedings of the 2024 8th International Conference on Advances in Artificial Intelligence,2024,,,,,,
10.1145/3728985,proceedings,,ICRAI '24: Proceedings of the 2024 10th International Conference on Robotics and Artificial Intelligence,2024,,,,,,
10.1145/3617694,proceedings,,"EAAMO '23: Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization",2023,,,,,,
10.1145/3640479,book,"Baecker, Ronald M. and Grudin, Jonathan",Digital Dreams Have Become Nightmares: What We Must Do,2024,,,,,"This book offers a compelling discussion of the digital dreams that have come true, their often unintended side effects (nightmares), and what must be done to counteract the nightmares. It is intended as an impetus to further conversation not only in homes and workplaces, but in academic courses and even legislative debates. Equally importantly, the book is a presentation of what digital technology professionals need to know about these topics and the actions they should undertake individually and in support of other citizens, societal initiatives, and government. The author begins by introducing the amazing progress made in digital technologies over the past 80 years. Pioneering engineers dreamed of potential uses of technology through their writing and technical achievements, further inspiring thousands of researchers to bring the dreams to life, and to dream new dreams as well. The second part of the book describes the myriad adverse side effects and unanticipated challenges that arose as those dreams were pursued and achieved. Examples include rampant misinformation on social media, ransomware, autonomous weapons, and the premature use of AI before it is reliable and safe.The book closes with a positive call to action, outlining ways to address the challenges through ethical career choices, careful analysis, thoughtful design, research, citizen engagement, legislation/regulation, and careful consideration of how bad actors may use technology. Readers of Digital Dreams Have Become Nightmares should become more knowledgeable, wiser, and also cautiously optimistic, determined to affect positive changes through their design, creation, and use of technology.“Are you feeling happy about the role of information technology in the world today? You should read this book for a dose of reality. Are you in despair about it? This book is the prescription for that condition, too! Nobody else could cover the landscape as Ron Baecker does.” - Clayton Lewis, Emeritus Professor, University of Colorado Boulder“This book is a captivating review of important computing developments. Many things talked about as new today have been around for a long time. Much can be learned from the past. The book also teaches a careful and consistent method that enables the reader to do this kind of work as the need arises. The book suggests the need will arise.” - John Leslie King, Emeritus Professor, University of Michigan",
10.1145/3581791,proceedings,,"MobiSys '23: Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services",2023,,,,,"On behalf of the entire organizing committee, it is with immense pleasure that we welcome you to the 21st ACM International Conference on Mobile Systems, Applications, and Services (ACM MobiSys 2023) hosted in Helsinki, Finland on June 18 - 22, 2023. ACM MobiSys is the leading conference in research on mobile systems, applications and services, and a flagship conference of ACM SIGMOBILE.",
10.1145/3729605,proceedings,,ICBDIE '25: Proceedings of the 2025 International Conference on Big Data and Informatization Education,2025,,,,,,
10.1145/3603555,proceedings,,MuC '23: Proceedings of Mensch und Computer 2023,2023,,,,,,
10.1145/3627915,proceedings,,CSAE '23: Proceedings of the 7th International Conference on Computer Science and Application Engineering,2023,,,,,,
10.1145/3613904.3642427,inproceedings,"Schneiders, Eike and Fourie, Christopher and Celestin, Stanley and Shah, Julie and Jung, Malte",Understanding Entrainment in Human Groups: Optimising Human-Robot Collaboration from Lessons Learned during Human-Human Collaboration,2024,,Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,10.1145/3613904.3642427,https://doi.org/10.1145/3613904.3642427,"Successful entrainment during collaboration positively affects trust, willingness to collaborate, and likeability towards collaborators. In this paper, we present a mixed-method study to investigate characteristics of successful entrainment leading to pair and group-based synchronisation. Drawing inspiration from industrial settings, we designed a fast-paced, short-cycle repetitive task. Using motion tracking, we investigated entrainment in both dyadic and triadic task completion. Furthermore, we utilise audio-video recordings and semi-structured interviews to contextualise participants’ experiences. This paper contributes to the Human-Computer/Robot Interaction (HCI/HRI) literature using a human-centred approach to identify characteristics of entrainment during pair- and group-based collaboration. We present five characteristics related to successful entrainment. These are related to the occurrence of entrainment, leader-follower patterns, interpersonal communication, the importance of the point-of-assembly, and the value of acoustic feedback. Finally, we present three design considerations for future research and design on collaboration with robots.",
10.1145/3640792,proceedings,,AutomotiveUI '24: Proceedings of the 16th International Conference on Automotive User Interfaces and Interactive Vehicular Applications,2024,,,,,,
10.1145/3726302,proceedings,,SIGIR '25: Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval,2025,,,,,"It is our great pleasure to welcome you to the 48th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (ACM SIGIR 2025), taking place in Padova, Italy, from July 13th to July 18th, 2025.This year's conference continues its tradition of being the premier international forum for presenting cutting-edge research and showcasing innovative systems and techniques in the broad field of Information Retrieval.SIGIR 2025 is an in-person conference. We believe that holding the conference in person offers significant advantages, including richer opportunities for direct engagement and networking, a more dynamic exchange of research ideas, and a more welcoming environment for newcomers. To accommodate those who, in exceptional cases, are unable to attend in person, we have arranged for the option of proxy presenters (i.e. a qualified person presents on their behalf).This year's conference spans six days, beginning with a day dedicated to the Doctoral Consortium and Tutorial presentations. The following three days feature sessions comprising three Keynote Talks, full papers, short papers, resource and reproducibility papers, perspective papers, lowresources environments papers, system demonstrations, and an industry track (SIRIP). The program also features two Women in IR (WIR) activities (a panel and a poster session). Finally, the last day is devoted to Workshops aimed at fostering discussion and encouraging collaboration on emerging research topics in Information Retrieval, as well as to the LiveRag challenge, organized by the Technology Innovation Institute, and focused on Retrieval Augmented Generation. On Friday the 18th the ICTIR 2025 Conference takes place.Social highlights include a welcome reception, a conference dinner, a student luncheon and student party, as well as the WIR reception and the ICTIR Social Dinner.The SIGIR 2025 technical program is highlighted by three keynote presentations delivered by esteemed speakers, to whom we extend our sincere gratitude: Stephen Robertson (Girton College, Cambridge, UK), Iryna Gurevych (Technical University of Darmstadt, Germany), and Ophir Frieder (Georgetown University, Washington DC, USA).",
10.1145/3569009,proceedings,,"TEI '23: Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction",2023,,,,,,
10.1145/3565995,proceedings,,ACI '22: Proceedings of the Ninth International Conference on Animal-Computer Interaction,2022,,,,,,
10.1145/3578741,proceedings,,MLNLP '22: Proceedings of the 2022 5th International Conference on Machine Learning and Natural Language Processing,2022,,,,,,
10.1145/3578837,proceedings,,ICEEL '22: Proceedings of the 2022 6th International Conference on Education and E-Learning,2022,,,,,,
10.1145/3594739,proceedings,,UbiComp/ISWC '23 Adjunct: Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing &amp; the 2023 ACM International Symposium on Wearable Computing,2023,,,,,,
10.1145/3615366,proceedings,,LADC '23: Proceedings of the 12th Latin-American Symposium on Dependable and Secure Computing,2023,,,,,,
10.1145/3745900,proceedings,,AHs '25: Proceedings of the Augmented Humans International Conference 2025,2025,,,,,,
10.1145/3626252,proceedings,,SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,,,,,"Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is ""Blazing New Trails in CS Education."" This broad theme captures the exceptional work being performed by this community to enhance our teaching, improve our assessments, attract diverse students, and all of the other laudable projects, initiatives, and undertakings that affect positive change. The breadth of the program is substantial - there truly should be something for everyone. In fact, your biggest challenge may be deciding which session to attend in each time slot because there is so much going on! We know that many of you want to attend as many sessions as possible while you are here in Portland, but we encourage you to also find a little bit of time for yourself so that you leave Portland refreshed, renewed and encouraged, rather than exhausted or burnt out.",
10.1145/3616855,proceedings,,WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining,2024,,,,,"It is our great pleasure to welcome you to the 17th ACM International Conference on Web Search and Data Mining - WSDM 2024. WSDM is one of the premier conferences in the fields of web search and data mining, with a dynamic and growing community from academia and industry. After two years of virtual conferences and in-person conferences in Singapore, the 2024 edition is an in-person conference with virtual elements. We hope you enjoy the conference at the ""Centro Internacional de Congresos de Yucatan (CIC)"" in Merida from March 4 to March 8, 2024.We are excited to kick off the program with a dynamic mix of Tutorials and Industry Day. Our seven tutorials will cover a broad range of search and data mining topics. Industry Day will provide valuable insights from leaders at major technology companies. The core technical program continues WSDM's tradition of a single-track format, featuring 109 thought-provoking papers from both academic and industry experts. We're honored to have inspiring keynote speakers each day: Nicolas Christin (CMU), Elizabeth Reid (Google), and Saiph Savage (Civic A.I. Lab). Additionally, 17 interactive demonstrations will showcase the latest prototypes and systems. The final day offers a stimulating Doctoral Consortium and six engaging workshops on topics including integrity in social networks, large language model for society, psychology-informed information access system, interactive and scalable information retrieval system and machine learning on graphs. WSDM 2024 proudly presents WSDM day on information retrieval and Web in the region. WSDM Cup Day highlights finalists' presentations addressing challenges in Conversational Multi-Doc QA. This diverse and stimulating program promises to be an enriching experience for all!.",
10.1145/3635636,proceedings,,C&amp;C '24: Proceedings of the 16th Conference on Creativity &amp; Cognition,2024,,,,,,
10.1145/3607822,proceedings,,SUI '23: Proceedings of the 2023 ACM Symposium on Spatial User Interaction,2023,,,,,,
10.1145/3728199,proceedings,,CNML '25: Proceedings of the 2025 3rd International Conference on Communication Networks and Machine Learning,2025,,,,,,
10.1145/3582700,proceedings,,AHs '23: Proceedings of the Augmented Humans International Conference 2023,2023,,,,,,
10.1145/3565698,proceedings,,Chinese CHI '22: Proceedings of the Tenth International Symposium of Chinese CHI,2022,,,,,,
10.1145/3672758,proceedings,,"CAICE '24: Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering",2024,,,,,,
10.1145/3587889,proceedings,,ICIEAEU '23: Proceedings of the 2023 10th International Conference on Industrial Engineering and Applications,2023,,,,,,
10.1145/3746469,proceedings,,EDCS '25: Proceedings of the 2nd Guangdong-Hong Kong-Macao Greater Bay Area Education Digitalization and Computer Science International Conference,2025,,,,,,
10.1145/3597512.3600210,inproceedings,"O'Donovan, Cian and Caleb-Solly, Praminda and Kumar, Praveen and Russell, Siabhainn and Sumpter, Linda and Williams, Robin",Empowering future care workforces: scoping human capabilities to leverage assistive robotics,2023,,Proceedings of the First International Symposium on Trustworthy Autonomous Systems,10.1145/3597512.3600210,https://doi.org/10.1145/3597512.3600210,"How and what health and care professionals do will be changed by the use of robotics technologies in their workplaces. This paper reports provisional results of a 12-month scoping project in which we explained to people working in care sectors what emerging robotics and autonomous systems (RAS) in health and social care look like at present and how they are designed to work. With participants such as nurses, physiotherapists and occupational therapists we explored how RAS might develop in ways that empower professionals and are safe, trustworthy, legal and ethical. Our research shows a diversity of tasks are valued by professionals and a range of human capabilities are required throughout care organisations in order to support them. Our findings have implications for how health and care professionals and operators might develop training programmes that best align the use of emerging RAS with practices of care, and how robotics systems might be responsibly designed to meet the needs of diverse professionals and service users. Today’s professionals told us that in the future they will want to continue doing what they signed up for. Responsible robotics research will ensure that technology enables and empowers them to do this as needed.",
10.1145/3701571,proceedings,,MUM '24: Proceedings of the International Conference on Mobile and Ubiquitous Multimedia,2024,,,,,,
10.1145/3706598.3714123,inproceedings,"Garrett, Rachael and Brundell, Patrick and Castle-Green, Simon and Hawkins, Kat and Tennent, Paul and Zhou, Feng and Lampinen, Airi and H\""{o}\""{o}k, Kristina and Benford, Steve",Friction in Processual Ethics: Reconfiguring Ethical Relations in Interdisciplinary Research,2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3714123,https://doi.org/10.1145/3706598.3714123,"Friction – disagreement and breakdown – is an omnipresent aspect of conducting interdisciplinary research yet is rarely presented in formal research reporting. We analyse a performance-led research process where professional dancers with different disabilities explored how to improvise with an industrial robot, with the support of an interdisciplinary team of human-computer and human-robot interaction researchers. We focus on one site of friction in our research process; how to dance – safely – with robots? By presenting our research process, we exemplify the different ways in which we encountered this friction and how we reconfigured the research process around it. We contribute five ways in which we arrived at a generative ethical outcome, which may be helpful in productively engaging with friction in interdisciplinary collaboration.",
10.1145/3756423,proceedings,,ICAISM '25: Proceedings of the 2025 International Conference on Artificial Intelligence and Smart Manufacturing,2025,,,,,,
10.1145/3706598.3713632,inproceedings,"Garrett, Rachael and Hawkins, Kat and Brundell, Patrick and Castle-Green, Simon and Tennent, Paul and Zhou, Feng and Lampinen, Airi and H\""{o}\""{o}k, Kristina and Benford, Steve",In the Moment of Glitch: Engaging with Misalignments in Ethical Practice,2025,,Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,10.1145/3706598.3713632,https://doi.org/10.1145/3706598.3713632,"Glitches – moments when technologies do not work as desired – will become increasingly common as industrially-designed robots move into complex contexts. Taking glitches to be potential sites of critical ethical reflection, we examine a glitch that occurred in the context of a collaborative research project where professional dancers with different disabilities improvised with a robotic arm. Through a first-person account, we analyse how the dancer, the robot, and the rest of the research team enacted ethics in the moment of glitch. Through this analysis, we discovered a deep and implicit ethical misalignment wherein our enactments of ethics in response to the glitch did not align with the values of the project. This prompted a critical re-engagement with our research process through which we forged a dialogue between different ethical perspectives that acted as an invitation to bring us back into ethical alignment with the project’s values.",
10.1145/3679409,proceedings,,ISCER '24: Proceedings of the 2024 3rd International Symposium on Control Engineering and Robotics,2024,,,,,,
10.1145/3617023,proceedings,,WebMedia '23: Proceedings of the 29th Brazilian Symposium on Multimedia and the Web,2023,,,,,,
10.1145/3582580,proceedings,,ICETM '22: Proceedings of the 2022 5th International Conference on Education Technology Management,2022,,,,,,
10.5555/3709347,proceedings,,AAMAS '25: Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems,2025,,,,,"Welcome to AAMAS-2025, the 24th edition of the International Conference on Autonomous Agents and Multiagent Systems!AAMAS is the largest and most influential conference in the area of agents and multiagent systems, bringing together researchers and practitioners in all areas of agent technology and providing an internationally renowned high-profile forum for publishing and learning about the latest developments in the field. AAMAS is the flagship conference of the non-profit International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS).We are happy that the 2025 edition of AAMAS will be coming to Detroit, MI. Previous editions were held in Bologna (2002), Melbourne (2003), New York (2004), Utrecht (2005), Hakodate (2006), Honolulu (2007), Estoril (2008), Budapest (2009), Toronto (2010), Taipei (2011), Valencia (2012), Saint Paul (2013), Paris (2014), Istanbul (2015), Singapore (2016), S\~{a}o Paulo (2017), Stockholm (2018), Montr\'{e}al (2019), Auckland/online (2020), London/online (2021), Auckland/online (2022), London (2023), and Auckland (2024).The main track of the conference includes peer-reviewed technical papers describing significant and original research on all aspects of the theory and practice of autonomous agents and multiagent systems, divided into the following areas of interest:Learning and Adaptation (LEARN)Game Theory and Economic Paradigms (GTEP)Coordination, Organizations, Institutions, Norms, and Ethics (COINE)Search, Optimization, Planning, and Scheduling (SOPS)Representation, Perception, and Reasoning (RPR)Engineering and Analysis of Multiagent Systems (EMAS)Modeling and Simulation of Societies (SIM)Human-Agent Interaction (HAI)Robotics and Control (ROBOT)Innovative Applications (IA)As in previous years, we worked with a three-tier program committee, consisting of 29 area chairs, 147 senior program committee members, and over 600 regular program committee members. Their work was supported by a substantial number of auxiliary reviewers. When composing the committee, we followed the tradition of AAMAS of not having anyone serve in a senior programme committee or area chair role for more than two years in a row, and we were pleased to see that many senior colleagues accepted our invitation to serve as regular programme committee members.For the main track, we received a total of 1361 abstract submissions. Some didn't materialize while a number of others were desk-rejected (mostly due to anonymity violations and similar infringements of the rules laid down in the Call for Papers). The program committee then reviewed the remaining 1021 submissions. Almost all submissions received at least three reviews, as well as a meta-review summarizing the assessment of the program committee. Authors had the opportunity to respond to initial versions of their reviews during a rebuttal phase, and the rebuttal phase additional gave the authors and reviewers an opportunity to engage in further discussion.",
10.1145/3597503,proceedings,,ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,2024,,,,,,
10.1145/3653691,article,"Liang, Kai-Hui and Shi, Weiyan and Oh, Yoo Jung and Wang, Hao-Chuan and Zhang, Jingwen and Yu, Zhou",Dialoging Resonance in Human-Chatbot Conversation: How Users Perceive and Reciprocate Recommendation Chatbot's Self-Disclosure Strategy,2024,Proc. ACM Hum.-Comput. Interact.,,10.1145/3653691,https://doi.org/10.1145/3653691,"Using chatbots to make recommendations is increasingly popular. The design of recommendation chatbots has mainly been taking an information-centric approach by focusing on the recommended content per se. Limited attention is on how social connection and relational strategies, such as self-disclosure from a chatbot, may influence users' perception and acceptance of the recommendation. In this work, we designed, implemented, and evaluated a social chatbot capable of performing three different levels of self-disclosure: factual information (low), cognitive opinions (medium), and emotions (high). In the evaluation, we recruited 372 participants to converse with the chatbot on two topics: movies and COVID-19 experiences. In each topic, the chatbot conducted small talks and made relevant recommendations to the topic. Participants were randomly assigned to four experimental conditions where the chatbot used factual, cognitive, emotional, and adaptive strategies to perform self-disclosures. By training a text classifier to identify users' level of self-disclosure in real-time, the adaptive chatbot can dynamically match its self-disclosure language to the level of disclosure exhibited by the users. Our results show that users reciprocate with higher-level self-disclosure when a recommendation chatbot displays emotions throughout the conversation. The utilization of emotional disclosure by the chatbot resulted in enhanced enjoyment during interactions and a more favorable perception of the bot. This, in turn, led to greater effectiveness in making recommendations, including a higher likelihood of accepting the recommendation. We discuss the understandings obtained and implications to future design.",
10.1145/3716895,proceedings,,ICAICE '24: Proceedings of the 5th International Conference on Artificial Intelligence and Computer Engineering,2024,,,,,,
10.1145/3623509,proceedings,,"TEI '24: Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction",2024,,,,,,
10.1145/3644116,proceedings,,ISAIMS '23: Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science,2023,,,,,,
